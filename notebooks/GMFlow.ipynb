{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906cdf7c",
   "metadata": {},
   "source": [
    "#### GMFlow Implementation\n",
    "\n",
    "https://arxiv.org/abs/2111.13680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb81621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2838ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 15:12:26.758662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 15:12:27.086345: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-28 15:12:28.476871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.3/lib64:/shared/centos7/nodejs/14.15.4/lib\n",
      "2022-09-28 15:12:28.477000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /shared/centos7/cuda/11.3/lib64:/shared/centos7/nodejs/14.15.4/lib\n",
      "2022-09-28 15:12:28.477011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from nnflow import GMFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f1e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezflow.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237822ae-a08b-482d-a0f7-1d34a39ff61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac187c89-f8aa-48d9-81be-ec902800f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return str(sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000) + \"M params\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc08db9-f487-4684-a9a5-6424075df471",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Use `num_scales=1` and `upsample_factor=8` for GMFlow without refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04aaa5cf-8a39-4ccf-84bf-9199e5c70b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model('GMFlow', cfg_path='../configs/gmflow/models/gmflow_v01.yaml', custom_cfg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56adf0a8-8364-424e-b03a-567f812e0d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.680288M params'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3c6ce4-a185-4d31-8768-180ddfed27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GMFlow(\n",
    "#     feature_channels=128,\n",
    "#     num_scales=1,\n",
    "#     upsample_factor=8,\n",
    "#     num_head=1,\n",
    "#     attention_type='swin',\n",
    "#     ffn_dim_expansion=4,\n",
    "#     num_transformer_layers=6,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efd92175-c35c-4139-8d17-5486366a9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, img2 = torch.randn(1,3,368,496), torch.randn(1,3,368,496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5900b8b8-246d-432c-b3d8-7be45a5b65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_result = model(img1, img2,\n",
    "#        attn_splits_list=[2],\n",
    "#        corr_radius_list=[-1],\n",
    "#        prop_radius_list=[-1],\n",
    "#    )\n",
    "\n",
    "flow_result = model(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c43089a8-15c7-4295-8400-7c3d1e2c3878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['flow_preds'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a7d7c8b-46a0-4156-83af-cc06b38c7ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flow_result['flow_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d02c3967-d9d7-4eea-bb4d-2c8d3f01e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 368, 496])\n",
      "torch.Size([1, 2, 368, 496])\n"
     ]
    }
   ],
   "source": [
    "for flow in flow_result['flow_preds']:\n",
    "    print(flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3831cfd-d843-4ba2-9934-30728f3af20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['flow_preds', 'flow_upsampled'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 256, 256]), torch.Size([1, 2, 256, 256]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "flow_result = model(img1, img2)\n",
    "print(flow_result.keys())\n",
    "\n",
    "flow_result['flow_preds'][0].shape, flow_result['flow_upsampled'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd746c-31ee-473b-88b6-c6321fca3505",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "____\n",
    "\n",
    "##### Use `num_scales=2` and `upsample_factor=8` for GMFlow with refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c1f809-155c-4d59-80b1-e779e7802dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_refinement = GMFlow(\n",
    "    feature_channels=128,\n",
    "    num_scales=2,\n",
    "    upsample_factor=4,\n",
    "    num_head=1,\n",
    "    attention_type='swin',\n",
    "    ffn_dim_expansion=4,\n",
    "    num_transformer_layers=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b0b4ff1-ed15-41af-aa40-81739582ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_result = model_with_refinement(img1, img2,\n",
    "       attn_splits_list=[2, 8],\n",
    "       corr_radius_list=[-1, 4],\n",
    "       prop_radius_list=[-1, 1],\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed8a2a25-1f50-4d70-a405-c2e93c7eaeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for flow in flow_result['flow_preds']:\n",
    "    print(flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714eec0-5757-4cdf-b16a-384aa2e7b9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
