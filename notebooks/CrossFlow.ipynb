{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f258dc2-bf3f-4a8f-8b0b-1c7b2d248294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/goswami.p/miniconda3\n",
      "cs5330_pa5_1             /home/goswami.p/miniconda3/envs/cs5330_pa5_1\n",
      "dicl                     /home/goswami.p/miniconda3/envs/dicl\n",
      "ezflow                *  /home/goswami.p/miniconda3/envs/ezflow\n",
      "flow                     /home/goswami.p/miniconda3/envs/flow\n",
      "inpaint                  /home/goswami.p/miniconda3/envs/inpaint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347169f6-d530-4f36-b272-659c0f6be507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 28 08:33:34 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    56W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dd74e6-b0d2-4a87-9e20-221e7f0a5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ezflow.modules import BaseModule\n",
    "from ezflow.encoder import build_encoder\n",
    "\n",
    "from torch.nn.functional import pad\n",
    "from torch.nn.init import trunc_normal_\n",
    "\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from natten.functional import natten2dqkrpb, natten2dav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf89e5b4-a4a3-4916-bc00-4f776eef563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnflow.models.gmflow.transformer import FeatureFlowAttention\n",
    "from nnflow.models.gmflow.matching import global_correlation_softmax\n",
    "from nnflow.models.gmflow.position import PositionEmbeddingSine\n",
    "from nnflow.models.gmflow.nat import ConvTokenizer, ConvDownsampler, Mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5b98f-408d-43f1-a7db-810b2a65424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return str(sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000) + \"M params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ff11d2-a889-45d2-b9e1-d5e23b07c328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a639f3-47f2-41ec-b502-6f6245c14700",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Modified Neighborhood Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b40797-31e1-4507-b377-9bf1967b888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NATLayer with Cross Attention\n",
    "# shortcut in NAT == source in GMFlow Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ffe8d6-ecb9-44a1-8906-ac8eac91fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedNeighborhoodAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Neighborhood Attention 2D Module\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, kernel_size, num_heads,\n",
    "                 qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.,\n",
    "                 dilation=None):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // self.num_heads\n",
    "        self.scale = qk_scale or self.head_dim ** -0.5\n",
    "        assert kernel_size > 1 and kernel_size % 2 == 1, \\\n",
    "            f\"Kernel size must be an odd number greater than 1, got {kernel_size}.\"\n",
    "        self.kernel_size = kernel_size\n",
    "        if type(dilation) is str:\n",
    "            self.dilation = None\n",
    "            self.window_size = None\n",
    "        else:\n",
    "            assert dilation is None or dilation >= 1, \\\n",
    "                f\"Dilation must be greater than or equal to 1, got {dilation}.\"\n",
    "            self.dilation = dilation or 1\n",
    "            self.window_size = self.kernel_size * self.dilation\n",
    "\n",
    "        # self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.q_proj = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.k_proj = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.v_proj = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        \n",
    "        self.rpb = nn.Parameter(torch.zeros(num_heads, (2 * kernel_size - 1), (2 * kernel_size - 1)))\n",
    "        trunc_normal_(self.rpb, std=.02, mean=0., a=-2., b=2.)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        assert q.shape == k.shape == k.shape\n",
    "        B, Hp, Wp, C = q.shape\n",
    "        H, W = int(Hp), int(Wp)\n",
    "        pad_l = pad_t = pad_r = pad_b = 0\n",
    "        dilation = self.dilation\n",
    "        window_size = self.window_size\n",
    "        if window_size is None:\n",
    "            dilation = max(min(H, W) // self.kernel_size, 1)\n",
    "            window_size = dilation * self.kernel_size\n",
    "        if H < window_size or W < window_size:\n",
    "            pad_l = pad_t = 0\n",
    "            pad_r = max(0, window_size - W)\n",
    "            pad_b = max(0, window_size - H)\n",
    "            q = pad(q, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
    "            k = pad(k, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
    "            v = pad(v, (0, 0, pad_l, pad_r, pad_t, pad_b))\n",
    "            _, H, W, _ = q.shape\n",
    "        # qkv = self.qkv(x).reshape(B, H, W, 3, self.num_heads, self.head_dim).permute(3, 0, 4, 1, 2, 5)\n",
    "        # q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        q = self.q_proj(q).reshape(B, H, W, self.num_heads, self.head_dim).permute(0, 3, 1, 2, 4)\n",
    "        k = self.k_proj(k).reshape(B, H, W, self.num_heads, self.head_dim).permute(0, 3, 1, 2, 4)\n",
    "        v = self.v_proj(v).reshape(B, H, W, self.num_heads, self.head_dim).permute(0, 3, 1, 2, 4)\n",
    "        \n",
    "        # print(q.shape, k.shape, v.shape)\n",
    "        q = q * self.scale\n",
    "        attn = natten2dqkrpb(q, k, self.rpb, dilation)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = natten2dav(attn, v, dilation)\n",
    "        x = x.permute(0, 2, 3, 1, 4).reshape(B, H, W, C)\n",
    "        if pad_r or pad_b:\n",
    "            x = x[:, :Hp, :Wp, :]\n",
    "\n",
    "        return self.proj_drop(self.proj(x))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'kernel_size={self.kernel_size}, dilation={self.dilation}, head_dim={self.head_dim}, num_heads={self.num_heads}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e4a907-df3a-4786-af89-2b756bd56cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embed = ConvTokenizer(in_chans=3, embed_dim=64, norm_layer=nn.LayerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df7cf03-4d4c-40f1-bbfb-8ab28489cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = ModifiedNeighborhoodAttention(\n",
    "    dim=64,\n",
    "    kernel_size=7,\n",
    "    num_heads=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9d5053-02a3-4792-844b-4b2ab2aa98da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,3,256,256)\n",
    "out = patch_embed(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5382a00a-ec2b-4150-b8e7-aab551eaf00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attn(out, out, out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f715dbbc-28b0-4cd3-ac89-8c3b6f798a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedNeighborhoodAttention(\n",
       "  kernel_size=7, dilation=1, head_dim=32, num_heads=2\n",
       "  (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "  (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a875c-ec1c-4be8-94d0-334e11bba330",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747de078-2af3-4e85-8e5e-77c0716c7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c47bb8a4-e192-4aa6-945f-b55cfef9e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedNATLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_heads,\n",
    "        kernel_size=7,\n",
    "        dilation=None,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        act_layer=nn.GELU,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        no_ffn=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.no_ffn = no_ffn\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = ModifiedNeighborhoodAttention(\n",
    "            dim,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            qk_scale=qk_scale,\n",
    "            attn_drop=attn_drop,\n",
    "            proj_drop=drop,\n",
    "        )\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
    "        \n",
    "        # no ffn after self-attn, with ffn after cross-attn\n",
    "        if not self.no_ffn:\n",
    "            self.norm2 = norm_layer(dim)\n",
    "            self.mlp = Mlp(\n",
    "                in_features=dim,\n",
    "                hidden_features=int(dim * mlp_ratio),\n",
    "                act_layer=act_layer,\n",
    "                drop=drop,\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        shortcut = source\n",
    "\n",
    "        x = torch.cat([source, target], dim=0)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        source, target = x.chunk(chunks=2, dim=0)   \n",
    "        query, key, value = source, target, target\n",
    "\n",
    "        x = self.attn(query, key, value)\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        \n",
    "        # no ffn after self-attn, with ffn after cross-attn\n",
    "        if not self.no_ffn:\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "            \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00d8f58-f232-4a32-a036-048fc2d6ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer = ModifiedNATLayer(\n",
    "    dim=64,\n",
    "    num_heads=2,\n",
    "    mlp_ratio=3.0, \n",
    "    no_ffn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc40391-29ac-4fd8-b606-2eb23e4dae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedNATLayer(\n",
       "  (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): ModifiedNeighborhoodAttention(\n",
       "    kernel_size=7, dilation=1, head_dim=32, num_heads=2\n",
       "    (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9712fa38-9cc1-46b7-bdab-b2086fcc452a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,3,256,256)\n",
    "out = patch_embed(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afed43cd-8538-492e-8dfd-6d975e926236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = attn_layer(source=out, target=out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96330207-6c8e-4bbf-b64a-f1292992ef2f",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7398bf0-046f-4893-9835-b351c557a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Transformer Block with alternating Self-Cross layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a40a09-0fa3-4fbb-927e-7cecb219d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedNATBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth,\n",
    "        num_heads,\n",
    "        kernel_size,\n",
    "        dilations=None,\n",
    "        downsample=True,\n",
    "        mlp_ratio=4.0,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop=0.0,\n",
    "        attn_drop=0.0,\n",
    "        drop_path=0.0,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        self_no_ffn=True,\n",
    "        cross_no_ffn=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            # Self Attention Block\n",
    "            self.blocks.append(\n",
    "                 ModifiedNATLayer(\n",
    "                    dim=dim,\n",
    "                    num_heads=num_heads,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=None if dilations is None else dilations[i],\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    qk_scale=qk_scale,\n",
    "                    drop=drop,\n",
    "                    attn_drop=attn_drop,\n",
    "                    drop_path=drop_path[i]\n",
    "                    if isinstance(drop_path, list)\n",
    "                    else drop_path,\n",
    "                    norm_layer=norm_layer,\n",
    "                    no_ffn=self_no_ffn\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Cross Attention Block\n",
    "            self.blocks.append(\n",
    "                 ModifiedNATLayer(\n",
    "                    dim=dim,\n",
    "                    num_heads=num_heads,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=None if dilations is None else dilations[i],\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    qk_scale=qk_scale,\n",
    "                    drop=drop,\n",
    "                    attn_drop=attn_drop,\n",
    "                    drop_path=drop_path[i]\n",
    "                    if isinstance(drop_path, list)\n",
    "                    else drop_path,\n",
    "                    norm_layer=norm_layer,\n",
    "                    no_ffn=cross_no_ffn\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        self.downsample = (\n",
    "            None if not downsample else ConvDownsampler(dim=dim, norm_layer=norm_layer)\n",
    "        )\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        for i in range(len(self.blocks)):\n",
    "            \n",
    "            # self attention\n",
    "            if i % 2 == 0:\n",
    "                source = self.blocks[i](source, source)\n",
    "                \n",
    "            # cross attention and feed forward\n",
    "            else:\n",
    "                source = self.blocks[i](source, target)\n",
    "            \n",
    "        if self.downsample is None:\n",
    "            return source\n",
    "        \n",
    "        return self.downsample(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa3cbaa-4129-407d-b61a-62963f967aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_blk = ModifiedNATBlock(\n",
    "    dim=64,\n",
    "    depth=3,\n",
    "    num_heads=2,\n",
    "    kernel_size=7,\n",
    "    mlp_ratio=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed43ecfe-9e39-4a6b-9b8a-7ce2f8bb4d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2515M params'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(transformer_blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "033f8f24-3018-48cd-b04a-a4d2d5820622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,3,512,512)\n",
    "out = patch_embed(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "846e5e50-b788-4c26-891c-ec4bdac087a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = transformer_blk(source=out, target=out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6746d-4c97-4e07-a156-62e134c51b47",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1a3a1b-071e-4af1-8a9c-ccea9922bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f98c7a-87f8-4df7-9ea8-db57648392f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedNAT(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        mlp_ratio,\n",
    "        depths,\n",
    "        num_heads,\n",
    "        drop_path_rate=0.2,\n",
    "        in_chans=3,\n",
    "        kernel_size=7,\n",
    "        dilations=None,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        self_no_ffn=True,\n",
    "        cross_no_ffn=False,\n",
    "        use_sine_pos_embed=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        if isinstance(dilations, str) and dilations == 'None':\n",
    "            dilations = None \n",
    "\n",
    "        self.num_levels = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_levels - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.use_sine_pos_embed = use_sine_pos_embed\n",
    "\n",
    "        self.patch_embed = ConvTokenizer(\n",
    "            in_chans=in_chans, embed_dim=embed_dim, norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        self.levels = nn.ModuleList()\n",
    "        for i in range(self.num_levels):\n",
    "            level = ModifiedNATBlock(\n",
    "                dim=int(embed_dim * 2**i),\n",
    "                depth=depths[i],\n",
    "                num_heads=num_heads[i],\n",
    "                kernel_size=kernel_size,\n",
    "                dilations=None if dilations is None else dilations[i],\n",
    "                mlp_ratio=self.mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                qk_scale=qk_scale,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[sum(depths[:i]) : sum(depths[: i + 1])],\n",
    "                norm_layer=norm_layer,\n",
    "                downsample=(i < self.num_levels - 1),\n",
    "                self_no_ffn=self_no_ffn,\n",
    "                cross_no_ffn=cross_no_ffn\n",
    "            )\n",
    "            self.levels.append(level)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {\"rpb\"}\n",
    "    \n",
    "    def _add_position_embed(self, img1, img2, feature_channels):\n",
    "        pos_enc = PositionEmbeddingSine(num_pos_feats=feature_channels // 2)\n",
    "        position = pos_enc(img1.permute(0,3,1,2))\n",
    "        \n",
    "        position = position.permute(0,2,3,1)\n",
    "        \n",
    "        img1 = img1 + position\n",
    "        img2 = img2 + position\n",
    "        return img1, img2\n",
    "        \n",
    "    def forward_features(self, img1, img2):\n",
    "        b, c, h, w =  img1.shape\n",
    "        \n",
    "        x = self.patch_embed(torch.cat([img1,img2], dim=0))  \n",
    "        x = self.pos_drop(x)\n",
    "        \n",
    "        img1, img2 = x.chunk(chunks=2, dim=0)\n",
    "        \n",
    "        if self.use_sine_pos_embed:\n",
    "            img1, img2 = self._add_position_embed(img1, img2, feature_channels=self.embed_dim)\n",
    "        \n",
    "        # Concat img1 and img2 in batch dimension to compute in parallel\n",
    "        concat1 = torch.cat([img1, img2], dim=0) # 2B, H, W, C \n",
    "        concat2 = torch.cat([img2, img1], dim=0) # 2B, H, W, C\n",
    "        \n",
    "        for level in self.levels:\n",
    "            concat1 = level(concat1, concat2)\n",
    "            \n",
    "            # update feature2\n",
    "            concat2 = torch.cat(concat1.chunk(chunks=2,dim=0)[::-1], dim=0)\n",
    "            \n",
    "        concat1 = self.norm(concat1)\n",
    "        \n",
    "        feature1, feature2 = concat1.chunk(chunks=2,dim=0) # B, H, W, C      \n",
    "        return feature1, feature2\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        \n",
    "\n",
    "        feature1, feature2 = self.forward_features(img1, img2)\n",
    "        \n",
    "        feature1 = feature1.permute(0,3,1,2)\n",
    "        feature2 = feature2.permute(0,3,1,2)\n",
    "\n",
    "        return feature1, feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebc66b03-596a-4aec-8f19-44c7118ebd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = ModifiedNAT(\n",
    "    embed_dim=64,\n",
    "    mlp_ratio=3,\n",
    "    depths=[8,12],\n",
    "    num_heads=[2,4],\n",
    "    drop_path_rate=0.2,\n",
    "    in_chans=3,\n",
    "    kernel_size=7,\n",
    "    use_sine_pos_embed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f54e91e-7a17-4241-be0b-05e52a4604d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.36352M params'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(nat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0270aa5-2515-4ad1-af77-b08e998b668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 46, 62]), torch.Size([1, 128, 46, 62]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = torch.randn(1,3,368,496)\n",
    "img2 = torch.randn(1,3,368,496)\n",
    "\n",
    "feat1, feat2 = nat(img1, img2)\n",
    "\n",
    "feat1.shape, feat2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7715ec2-c952-4741-8849-0871ca218bf5",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125aeb2-c993-4028-8b19-c827a89d0090",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## New End 2 End Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371ef7de-4255-499f-a1c4-e8cabd38da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossFlow(BaseModule):\n",
    "    def __init__(self, cfg):\n",
    "        \n",
    "        super(CrossFlow, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.num_scales = cfg.MODEL.NUM_SCALES\n",
    "        self.feature_channels = cfg.MODEL.FEATURE_CHANNELS\n",
    "        self.upsample_factor = cfg.MODEL.UPSAMPLE_FACTOR\n",
    "        self.num_head = cfg.MODEL.NUM_HEADS\n",
    "        self.attention_type = cfg.MODEL.ATTENTION_TYPE\n",
    "        self.ffn_dim_expansion = cfg.MODEL.FFN_DIM_EXPANSION\n",
    "        self.num_transformer_layers = cfg.MODEL.NUM_TRANSFORMER_LAYERS\n",
    "\n",
    "        self.attn_splits_list=cfg.MODEL.ATTN_SPLITS_LIST\n",
    "        self.corr_radius_list=cfg.MODEL.CORR_RADIUS_LIST\n",
    "        self.prop_radius_list=cfg.MODEL.PROP_RADIUS_LIST\n",
    "        self.pred_bidir_flow=cfg.MODEL.PRED_BIDIR_FLOW\n",
    "        \n",
    "\n",
    "        # Transformer Backbone with alternating self attention and cross attention\n",
    "        self.backbone = ModifiedNAT(\n",
    "            embed_dim=cfg.ENCODER.EMBED_DIMS,\n",
    "            mlp_ratio=cfg.ENCODER.MLP_RATIO,\n",
    "            depths=cfg.ENCODER.DEPTHS,\n",
    "            num_heads=cfg.ENCODER.NUM_HEADS,\n",
    "            drop_path_rate=cfg.ENCODER.DROP_PATH_RATE,\n",
    "            in_chans=cfg.ENCODER.IN_CHANNELS,\n",
    "            kernel_size=cfg.ENCODER.KERNEL_SIZE,\n",
    "            dilations=cfg.ENCODER.DILATIONS,\n",
    "            self_no_ffn=cfg.ENCODER.SELF_NO_FFN,\n",
    "            cross_no_ffn=cfg.ENCODER.CROSS_NO_FFN,\n",
    "            use_sine_pos_embed=cfg.ENCODER.USE_SINE_POS_EMBED\n",
    "        )\n",
    "\n",
    "        # flow propagation with self-attn\n",
    "        self.feature_flow_attn = FeatureFlowAttention(in_channels=self.feature_channels)\n",
    "\n",
    "        # convex upsampling: concat feature0 and flow as input\n",
    "        self.upsampler = nn.Sequential(nn.Conv2d(2 + self.feature_channels, 256, 3, 1, 1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(256, self.upsample_factor ** 2 * 9, 1, 1, 0))\n",
    "\n",
    "    \n",
    "    def upsample_flow(self, flow, feature, bilinear=False, upsample_factor=8,\n",
    "                      ):\n",
    "        if bilinear:\n",
    "            up_flow = F.interpolate(flow, scale_factor=upsample_factor,\n",
    "                                    mode='bilinear', align_corners=True) * upsample_factor\n",
    "\n",
    "        else:\n",
    "            # convex upsampling\n",
    "            concat = torch.cat((flow, feature), dim=1)\n",
    "\n",
    "            mask = self.upsampler(concat)\n",
    "            b, flow_channel, h, w = flow.shape\n",
    "            mask = mask.view(b, 1, 9, self.upsample_factor, self.upsample_factor, h, w)  # [B, 1, 9, K, K, H, W]\n",
    "            mask = torch.softmax(mask, dim=2)\n",
    "\n",
    "            up_flow = F.unfold(self.upsample_factor * flow, [3, 3], padding=1)\n",
    "            up_flow = up_flow.view(b, flow_channel, 9, 1, 1, h, w)  # [B, 2, 9, 1, 1, H, W]\n",
    "\n",
    "            up_flow = torch.sum(mask * up_flow, dim=2)  # [B, 2, K, K, H, W]\n",
    "            up_flow = up_flow.permute(0, 1, 4, 2, 5, 3)  # [B, 2, K, H, K, W]\n",
    "            up_flow = up_flow.reshape(b, flow_channel, self.upsample_factor * h,\n",
    "                                      self.upsample_factor * w)  # [B, 2, K*H, K*W]\n",
    "\n",
    "        return up_flow\n",
    "\n",
    "    def forward(self, img0, img1):\n",
    "\n",
    "        results_dict = {}\n",
    "        flow_preds = []\n",
    "\n",
    "        # extract features\n",
    "        feature0, feature1 = self.backbone(img0, img1)          \n",
    "\n",
    "        assert len(self.attn_splits_list) == len(self.corr_radius_list) == len(self.prop_radius_list) == self.num_scales\n",
    "\n",
    "\n",
    "        upsample_factor = self.upsample_factor\n",
    "\n",
    "        attn_splits = self.attn_splits_list[0]\n",
    "        corr_radius = self.corr_radius_list[0]\n",
    "        prop_radius = self.prop_radius_list[0]\n",
    "\n",
    "            \n",
    "        # Global matching correlation and softmax\n",
    "        # when predicting bidirectional flow, flow is the \n",
    "        # concatenation of forward flow and backward flow in batch dim [2*B,2,H,W]\n",
    "        flow = global_correlation_softmax(feature0, feature1, self.pred_bidir_flow)[0]\n",
    "        \n",
    "\n",
    "        # upsample to the original resolution for supervison\n",
    "        if self.training:  # only need to upsample intermediate flow predictions at training time\n",
    "            flow_bilinear = self.upsample_flow(flow, None, bilinear=True, upsample_factor=upsample_factor)\n",
    "            flow_preds.append(flow_bilinear)\n",
    "\n",
    "        # flow propagation with self-attn\n",
    "        if self.pred_bidir_flow:\n",
    "            feature0 = torch.cat((feature0, feature1), dim=0)  # [2*B, C, H, W] for propagation\n",
    "            \n",
    "        flow = self.feature_flow_attn(feature0, flow.detach(),\n",
    "                                      local_window_attn=prop_radius > 0,\n",
    "                                      local_window_radius=prop_radius)\n",
    "\n",
    "\n",
    "        flow_up = self.upsample_flow(flow, feature0)\n",
    "        flow_preds.append(flow_up)\n",
    "\n",
    "        results_dict.update({'flow_preds': flow_preds})\n",
    "\n",
    "        if not self.training:\n",
    "            results_dict[\"flow_upsampled\"] = results_dict[\"flow_preds\"][0]\n",
    "\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70bcbc6c-1927-47fb-9e2d-4b42513daac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ezflow.engine import get_training_cfg as get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b6c9fd9-8a46-4cdc-8b0d-099fef57044c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'NAME': 'GMFlowV2', 'ENCODER': CfgNode({'NAME': 'NAT', 'IN_CHANNELS': 3, 'DEPTHS': [3, 4], 'NUM_HEADS': [2, 4], 'EMBED_DIMS': 64, 'MLP_RATIO': 3, 'DROP_PATH_RATE': 0.2, 'KERNEL_SIZE': 7, 'DILATIONS': [[1, 8, 1], [1, 4, 1, 4]], 'USE_SINE_POS_EMBED': True, 'SELF_NO_FFN': True, 'CROSS_NO_FFN': False}), 'MODEL': CfgNode({'FEATURE_CHANNELS': 128, 'NUM_SCALES': 1, 'UPSAMPLE_FACTOR': 8, 'NUM_HEADS': 1, 'ATTENTION_TYPE': 'swin', 'FFN_DIM_EXPANSION': 4, 'NUM_TRANSFORMER_LAYERS': 6, 'ATTN_SPLITS_LIST': [2], 'CORR_RADIUS_LIST': [-1], 'PROP_RADIUS_LIST': [-1], 'PRED_BIDIR_FLOW': False})})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_cfg(\"../configs/gmflow/models/crossflow_v02.yaml\")\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64f41182-ccaf-47a9-846f-57739308c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossFlow(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbeb4661-8766-4630-8235-7cb33574a203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.684236M params'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "304d36dc-f277-462d-9733-cdf77e4de3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 368, 496]), torch.Size([1, 2, 368, 496]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = torch.randn(1,3,368,496)\n",
    "img2 = torch.randn(1,3,368,496)\n",
    "\n",
    "results = model(img1, img2)\n",
    "results['flow_preds'][0].shape, results['flow_preds'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd2fed85-f856-40e3-9cc4-7432940425e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2996424-e951-41c6-8f92-330becc5c079",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00afe74b-fe0b-4f7f-a81f-e4f62078eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "\n",
    "from ezflow.engine import Trainer\n",
    "from nnflow import eval_model, CustomDataloaderCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75bdae0b-ad63-41b2-84d4-d401065ce856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CKPT_DIR': '../../results/crossflow/ckpts/exp004',\n",
      " 'CKPT_INTERVAL': 20000,\n",
      " 'CRITERION': {'CUSTOM': True,\n",
      "               'NAME': 'SequenceLoss',\n",
      "               'PARAMS': CfgNode({'gamma': 0.8, 'max_flow': 400.0})},\n",
      " 'DATA': {'APPEND_VALID_MASK': True,\n",
      "          'AUGMENTATION': {'PARAMS': {'TRAINING': {'AUTOFLOW_SPATIAL_PARAMS': {'black': False,\n",
      "                                                                               'enabled': False,\n",
      "                                                                               'rot': [0.4,\n",
      "                                                                                       0.03],\n",
      "                                                                               'scale': [0.3,\n",
      "                                                                                         0.03,\n",
      "                                                                                         0.1],\n",
      "                                                                               'squeeze': [0.3,\n",
      "                                                                                           0.0],\n",
      "                                                                               'trans': [0.4,\n",
      "                                                                                         0.03]},\n",
      "                                                   'COLOR_AUG_PARAMS': {'aug_prob': 0.2,\n",
      "                                                                        'brightness': 0.4,\n",
      "                                                                        'contrast': 0.4,\n",
      "                                                                        'enabled': True,\n",
      "                                                                        'hue': 0.15915494309189535,\n",
      "                                                                        'saturation': 0.4},\n",
      "                                                   'ERASER_AUG_PARAMS': {'aug_prob': 0.5,\n",
      "                                                                         'bounds': [50,\n",
      "                                                                                    100],\n",
      "                                                                         'enabled': True},\n",
      "                                                   'NOISE_PARAMS': {'aug_prob': 0.5,\n",
      "                                                                    'enabled': False,\n",
      "                                                                    'noise_std_range': 0.06},\n",
      "                                                   'ROTATE_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                     'enabled': False},\n",
      "                                                   'SPATIAL_AUG_PARAMS': {'aug_prob': 0.8,\n",
      "                                                                          'enabled': True,\n",
      "                                                                          'flip': True,\n",
      "                                                                          'h_flip_prob': 0.5,\n",
      "                                                                          'max_scale': 1.0,\n",
      "                                                                          'max_stretch': 0.2,\n",
      "                                                                          'min_scale': -0.1,\n",
      "                                                                          'stretch_prob': 0.8,\n",
      "                                                                          'v_flip_prob': 0.1},\n",
      "                                                   'TRANSLATE_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                        'enabled': False}},\n",
      "                                      'VALIDATION': {'COLOR_AUG_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                          'enabled': False},\n",
      "                                                     'ERASER_AUG_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                           'enabled': False},\n",
      "                                                     'ROTATE_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                       'enabled': False},\n",
      "                                                     'SPATIAL_AUG_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                            'enabled': False},\n",
      "                                                     'TRANSLATE_PARAMS': {'aug_prob': 0.0,\n",
      "                                                                          'enabled': False}}},\n",
      "                           'USE': True},\n",
      "          'BATCH_SIZE': 10,\n",
      "          'NORM_PARAMS': {'mean': [0.485, 0.456, 0.406],\n",
      "                          'std': [0.229, 0.224, 0.225],\n",
      "                          'use': True},\n",
      "          'NUM_WORKERS': 4,\n",
      "          'PIN_MEMORY': True,\n",
      "          'SHUFFLE': True,\n",
      "          'TRAIN_CROP_SIZE': [384, 512],\n",
      "          'TRAIN_DATASET': {'NAME': 'flyingchairs',\n",
      "                            'ROOT_DIR': '../../../Datasets/FlyingChairs_release/data'},\n",
      "          'VAL_CROP_SIZE': [384, 512],\n",
      "          'VAL_DATASET': {'NAME': 'flyingchairs',\n",
      "                          'ROOT_DIR': '../../../Datasets/FlyingChairs_release/data'}},\n",
      " 'DEVICE': 0,\n",
      " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
      "                 'MASTER_ADDR': 'localhost',\n",
      "                 'MASTER_PORT': '12355',\n",
      "                 'SYNC_BATCH_NORM': True,\n",
      "                 'USE': False,\n",
      "                 'WORLD_SIZE': 4},\n",
      " 'EPOCHS': None,\n",
      " 'FREEZE_BATCH_NORM': False,\n",
      " 'GRAD_CLIP': CfgNode({'USE': True, 'VALUE': 1.0}),\n",
      " 'LOG_DIR': '../../results/crossflow/logs/exp004',\n",
      " 'LOG_ITERATIONS_INTERVAL': 100,\n",
      " 'MIXED_PRECISION': False,\n",
      " 'NUM_STEPS': 50000,\n",
      " 'OPTIMIZER': {'LR': 0.0004,\n",
      "               'NAME': 'AdamW',\n",
      "               'PARAMS': {'amsgrad': False,\n",
      "                          'betas': [0.9, 0.999],\n",
      "                          'eps': 1e-08,\n",
      "                          'weight_decay': 0.0001}},\n",
      " 'RESUME_TRAINING': {'CONSOLIDATED_CKPT': None,\n",
      "                     'EPOCHS': 100,\n",
      "                     'START_EPOCH': None},\n",
      " 'SCHEDULER': {'NAME': 'OneCycleLR',\n",
      "               'PARAMS': {'anneal_strategy': 'linear',\n",
      "                          'cycle_momentum': False,\n",
      "                          'max_lr': 0.0004,\n",
      "                          'pct_start': 0.05,\n",
      "                          'total_steps': 50100},\n",
      "               'USE': True},\n",
      " 'TARGET_SCALE_FACTOR': 1.0,\n",
      " 'VALIDATE_INTERVAL': 1000,\n",
      " 'VALIDATE_ON': 'metric'}\n"
     ]
    }
   ],
   "source": [
    "model_cfg = get_cfg(\"../configs/gmflow/models/crossflow_v04.yaml\")\n",
    "training_cfg = get_cfg(\"../configs/gmflow/trainer/chairs_v2_1.yaml\")\n",
    "\n",
    "training_cfg.DATA.BATCH_SIZE = 10\n",
    "training_cfg.NUM_STEPS = 50000\n",
    "training_cfg.SCHEDULER.PARAMS.total_steps = 50100\n",
    "training_cfg.LOG_DIR = \"../../results/crossflow/logs/exp004\"\n",
    "training_cfg.CKPT_DIR = \"../../results/crossflow/ckpts/exp004\"\n",
    "training_cfg.FREEZE_BATCH_NORM = False\n",
    "\n",
    "pp.pprint(training_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c397b0-366f-4651-bbe1-783252b05b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_creator = CustomDataloaderCreator(\n",
    "    batch_size=training_cfg.DATA.BATCH_SIZE,\n",
    "    num_workers=training_cfg.DATA.NUM_WORKERS,\n",
    "    pin_memory=training_cfg.DATA.PIN_MEMORY,\n",
    "    append_valid_mask=training_cfg.DATA.APPEND_VALID_MASK,\n",
    "    shuffle=training_cfg.DATA.SHUFFLE\n",
    ")\n",
    "\n",
    "val_loader_creator = CustomDataloaderCreator(\n",
    "    batch_size=training_cfg.DATA.BATCH_SIZE,\n",
    "    num_workers=training_cfg.DATA.NUM_WORKERS,\n",
    "    pin_memory=training_cfg.DATA.PIN_MEMORY,\n",
    "    append_valid_mask=training_cfg.DATA.APPEND_VALID_MASK,\n",
    "    shuffle=training_cfg.DATA.SHUFFLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af3a7d6-10fc-4453-92af-03dc85a46a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_creator.add_FlyingChairs(\n",
    "    root_dir=\"../../../../Datasets/FlyingChairs_release/data\",\n",
    "    crop=True,\n",
    "    crop_type=\"random\",\n",
    "    crop_size=training_cfg.DATA.TRAIN_CROP_SIZE,\n",
    "    augment=training_cfg.DATA.AUGMENTATION.USE,\n",
    "    aug_params={\n",
    "        \"spatial_aug_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.SPATIAL_AUG_PARAMS,\n",
    "        \"color_aug_params\":training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.COLOR_AUG_PARAMS,\n",
    "        \"eraser_aug_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.ERASER_AUG_PARAMS,\n",
    "        \"noise_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.NOISE_PARAMS,\n",
    "        \"spatial_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.AUTOFLOW_SPATIAL_PARAMS,\n",
    "        \"translate_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.TRANSLATE_PARAMS,\n",
    "        \"rotate_params\": training_cfg.DATA.AUGMENTATION.PARAMS.TRAINING.ROTATE_PARAMS\n",
    "    },\n",
    "    norm_params=training_cfg.DATA.NORM_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78334d5f-eb97-428d-af18-602b90bc794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_creator.add_FlyingChairs(\n",
    "    root_dir=\"../../../../Datasets/FlyingChairs_release/data\",\n",
    "    split=\"validation\",\n",
    "    crop=True,\n",
    "    crop_type=\"center\",\n",
    "    crop_size=training_cfg.DATA.VAL_CROP_SIZE,\n",
    "    augment=False,\n",
    "    norm_params=training_cfg.DATA.NORM_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbfd2b59-a0a6-4230-8324-a48360e76be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossFlow(model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78b1d41-3c6c-4760-aad3-1cbd3fa014b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.844352M params'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da4005fd-4aaf-49a8-9e14-86ea87210462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image pairs loaded: 22230/22232\n",
      "\n",
      "Total image pairs loaded: 640/640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    training_cfg, \n",
    "    model, \n",
    "    train_loader = train_loader_creator.get_dataloader(), \n",
    "    val_loader = val_loader_creator.get_dataloader()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de0433-1114-4eff-9ecd-de8885471bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Training output 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf9c18-51fe-4c9c-9bcc-4f675c8b47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: SequenceLoss is initialized!\n",
      "Optimizer: AdamW is initialized!\n",
      "Scheduler: OneCycleLR is initialized!\n",
      "Training config:\n",
      "\n",
      "CKPT_DIR: ../../results/crossflow/ckpts/exp001\n",
      "CKPT_INTERVAL: 20000\n",
      "CRITERION:\n",
      "  CUSTOM: True\n",
      "  NAME: SequenceLoss\n",
      "  PARAMS:\n",
      "    gamma: 0.8\n",
      "    max_flow: 400.0\n",
      "DATA:\n",
      "  APPEND_VALID_MASK: True\n",
      "  AUGMENTATION:\n",
      "    PARAMS:\n",
      "      TRAINING:\n",
      "        AUTOFLOW_SPATIAL_PARAMS:\n",
      "          black: False\n",
      "          enabled: False\n",
      "          rot: [0.4, 0.03]\n",
      "          scale: [0.3, 0.03, 0.1]\n",
      "          squeeze: [0.3, 0.0]\n",
      "          trans: [0.4, 0.03]\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.2\n",
      "          brightness: 0.4\n",
      "          contrast: 0.4\n",
      "          enabled: True\n",
      "          hue: 0.15915494309189535\n",
      "          saturation: 0.4\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          bounds: [50, 100]\n",
      "          enabled: True\n",
      "        NOISE_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          enabled: False\n",
      "          noise_std_range: 0.06\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.8\n",
      "          enabled: True\n",
      "          flip: True\n",
      "          h_flip_prob: 0.5\n",
      "          max_scale: 1.0\n",
      "          max_stretch: 0.2\n",
      "          min_scale: -0.1\n",
      "          stretch_prob: 0.8\n",
      "          v_flip_prob: 0.1\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "      VALIDATION:\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "    USE: True\n",
      "  BATCH_SIZE: 10\n",
      "  NORM_PARAMS:\n",
      "    mean: [0.485, 0.456, 0.406]\n",
      "    std: [0.229, 0.224, 0.225]\n",
      "    use: True\n",
      "  NUM_WORKERS: 4\n",
      "  PIN_MEMORY: True\n",
      "  SHUFFLE: True\n",
      "  TRAIN_CROP_SIZE: [384, 512]\n",
      "  TRAIN_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "  VAL_CROP_SIZE: [384, 512]\n",
      "  VAL_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "DEVICE: 0\n",
      "DISTRIBUTED:\n",
      "  BACKEND: nccl\n",
      "  MASTER_ADDR: localhost\n",
      "  MASTER_PORT: 12355\n",
      "  SYNC_BATCH_NORM: True\n",
      "  USE: False\n",
      "  WORLD_SIZE: 4\n",
      "EPOCHS: None\n",
      "FREEZE_BATCH_NORM: False\n",
      "GRAD_CLIP:\n",
      "  USE: True\n",
      "  VALUE: 1.0\n",
      "LOG_DIR: ../../results/crossflow/logs/exp001\n",
      "LOG_ITERATIONS_INTERVAL: 100\n",
      "MIXED_PRECISION: False\n",
      "NUM_STEPS: 50000\n",
      "OPTIMIZER:\n",
      "  LR: 0.0004\n",
      "  NAME: AdamW\n",
      "  PARAMS:\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    eps: 1e-08\n",
      "    weight_decay: 0.0001\n",
      "RESUME_TRAINING:\n",
      "  CONSOLIDATED_CKPT: None\n",
      "  EPOCHS: 100\n",
      "  START_EPOCH: None\n",
      "SCHEDULER:\n",
      "  NAME: OneCycleLR\n",
      "  PARAMS:\n",
      "    anneal_strategy: linear\n",
      "    cycle_momentum: False\n",
      "    max_lr: 0.0004\n",
      "    pct_start: 0.05\n",
      "    total_steps: 50100\n",
      "  USE: True\n",
      "TARGET_SCALE_FACTOR: 1.0\n",
      "VALIDATE_INTERVAL: 1000\n",
      "VALIDATE_ON: metric\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Starting step 1 of 50001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/nnflow-0.0.0-py3.7.egg/nnflow/models/gmflow/position.py:39: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811797118/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 100, Total iterations: 100, Average batch training loss: 49.07904767990112\n",
      "Iterations: 200, Total iterations: 200, Average batch training loss: 34.91838252544403\n",
      "Iterations: 300, Total iterations: 300, Average batch training loss: 30.086434790293374\n",
      "Iterations: 400, Total iterations: 400, Average batch training loss: 27.542579951286317\n",
      "Iterations: 500, Total iterations: 500, Average batch training loss: 25.68077686882019\n",
      "Iterations: 600, Total iterations: 600, Average batch training loss: 24.51905212243398\n",
      "Iterations: 700, Total iterations: 700, Average batch training loss: 23.689530146462577\n",
      "Iterations: 800, Total iterations: 800, Average batch training loss: 23.024980469942093\n",
      "Iterations: 900, Total iterations: 900, Average batch training loss: 22.591071795887416\n",
      "Iterations: 1000, Total iterations: 1000, Average batch training loss: 22.220978223323822\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1000: Average validation loss = 7.17860546708107\n",
      "Iteration 1000: Average validation metric = 11.167132280766964\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 1100, Total iterations: 1100, Average batch training loss: 21.86314752708782\n",
      "Iterations: 1200, Total iterations: 1200, Average batch training loss: 21.540491242011388\n",
      "Iterations: 1300, Total iterations: 1300, Average batch training loss: 21.301965358073893\n",
      "Iterations: 1400, Total iterations: 1400, Average batch training loss: 21.061296075752804\n",
      "Iterations: 1500, Total iterations: 1500, Average batch training loss: 20.914963850339255\n",
      "Iterations: 1600, Total iterations: 1600, Average batch training loss: 20.702540305554866\n",
      "Iterations: 1700, Total iterations: 1700, Average batch training loss: 20.546103635395273\n",
      "Iterations: 1800, Total iterations: 1800, Average batch training loss: 20.38341358290778\n",
      "Iterations: 1900, Total iterations: 1900, Average batch training loss: 20.240886707556875\n",
      "Iterations: 2000, Total iterations: 2000, Average batch training loss: 20.08092079615593\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2000: Average validation loss = 6.717572797089815\n",
      "Iteration 2000: Average validation metric = 10.483916267752647\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 2100, Total iterations: 2100, Average batch training loss: 19.958660397756667\n",
      "Iterations: 2200, Total iterations: 2200, Average batch training loss: 19.87149004719474\n",
      "Iterations: 2300, Total iterations: 2300, Average batch training loss: 19.768129944179368\n",
      "Iterations: 2400, Total iterations: 2400, Average batch training loss: 19.64520295023918\n",
      "Iterations: 2500, Total iterations: 2500, Average batch training loss: 19.598178789138792\n",
      "Iterations: 2600, Total iterations: 2600, Average batch training loss: 19.508192962866563\n",
      "Iterations: 2700, Total iterations: 2700, Average batch training loss: 19.397010084258184\n",
      "Iterations: 2800, Total iterations: 2800, Average batch training loss: 19.29920263171196\n",
      "Iterations: 2900, Total iterations: 2900, Average batch training loss: 19.191497247465726\n",
      "Iterations: 3000, Total iterations: 3000, Average batch training loss: 19.069753976345062\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3000: Average validation loss = 5.936849132180214\n",
      "Iteration 3000: Average validation metric = 9.308717086911201\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 3100, Total iterations: 3100, Average batch training loss: 18.992089753766212\n",
      "Iterations: 3200, Total iterations: 3200, Average batch training loss: 18.89494441434741\n",
      "Iterations: 3300, Total iterations: 3300, Average batch training loss: 18.824427936582854\n",
      "Iterations: 3400, Total iterations: 3400, Average batch training loss: 18.71398776881835\n",
      "Iterations: 3500, Total iterations: 3500, Average batch training loss: 18.634517396245684\n",
      "Iterations: 3600, Total iterations: 3600, Average batch training loss: 18.549710723691515\n",
      "Iterations: 3700, Total iterations: 3700, Average batch training loss: 18.473269250070725\n",
      "Iterations: 3800, Total iterations: 3800, Average batch training loss: 18.38735685034802\n",
      "Iterations: 3900, Total iterations: 3900, Average batch training loss: 18.274200979134974\n",
      "Iterations: 4000, Total iterations: 4000, Average batch training loss: 18.177877590179442\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4000: Average validation loss = 5.074762057512999\n",
      "Iteration 4000: Average validation metric = 7.986652672290802\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 4100, Total iterations: 4100, Average batch training loss: 18.09095186582426\n",
      "Iterations: 4200, Total iterations: 4200, Average batch training loss: 17.994409805365972\n",
      "Iterations: 4300, Total iterations: 4300, Average batch training loss: 17.915353554237722\n",
      "Iterations: 4400, Total iterations: 4400, Average batch training loss: 17.83392666632479\n",
      "Iterations: 4500, Total iterations: 4500, Average batch training loss: 17.74550146452586\n",
      "Iterations: 4600, Total iterations: 4600, Average batch training loss: 17.682316649789396\n",
      "Iterations: 4700, Total iterations: 4700, Average batch training loss: 17.593180911997532\n",
      "Iterations: 4800, Total iterations: 4800, Average batch training loss: 17.52085929721594\n",
      "Iterations: 4900, Total iterations: 4900, Average batch training loss: 17.4578642093892\n",
      "Iterations: 5000, Total iterations: 5000, Average batch training loss: 17.38341633834839\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5000: Average validation loss = 4.51558979973197\n",
      "Iteration 5000: Average validation metric = 7.108978122472763\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 5100, Total iterations: 5100, Average batch training loss: 17.31257810050366\n",
      "Iterations: 5200, Total iterations: 5200, Average batch training loss: 17.252731730112664\n",
      "Iterations: 5300, Total iterations: 5300, Average batch training loss: 17.181580279548214\n",
      "Iterations: 5400, Total iterations: 5400, Average batch training loss: 17.102979747189416\n",
      "Iterations: 5500, Total iterations: 5500, Average batch training loss: 17.043025958494706\n",
      "Iterations: 5600, Total iterations: 5600, Average batch training loss: 16.9733978167602\n",
      "Iterations: 5700, Total iterations: 5700, Average batch training loss: 16.92098912807933\n",
      "Iterations: 5800, Total iterations: 5800, Average batch training loss: 16.858033793794696\n",
      "Iterations: 5900, Total iterations: 5900, Average batch training loss: 16.800621043463885\n",
      "Iterations: 6000, Total iterations: 6000, Average batch training loss: 16.740821460962295\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6000: Average validation loss = 4.3031956143677235\n",
      "Iteration 6000: Average validation metric = 6.7847802340984344\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 6100, Total iterations: 6100, Average batch training loss: 16.672731407509474\n",
      "Iterations: 6200, Total iterations: 6200, Average batch training loss: 16.62593670237449\n",
      "Iterations: 6300, Total iterations: 6300, Average batch training loss: 16.56923160757337\n",
      "Iterations: 6400, Total iterations: 6400, Average batch training loss: 16.518030279427766\n",
      "Iterations: 6500, Total iterations: 6500, Average batch training loss: 16.47383647955381\n",
      "Iterations: 6600, Total iterations: 6600, Average batch training loss: 16.432304195996487\n",
      "Iterations: 6700, Total iterations: 6700, Average batch training loss: 16.38400806156557\n",
      "Iterations: 6800, Total iterations: 6800, Average batch training loss: 16.33466146854793\n",
      "Iterations: 6900, Total iterations: 6900, Average batch training loss: 16.284737234253814\n",
      "Iterations: 7000, Total iterations: 7000, Average batch training loss: 16.23083668088913\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7000: Average validation loss = 4.0646266005933285\n",
      "Iteration 7000: Average validation metric = 6.407414179295301\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 7100, Total iterations: 7100, Average batch training loss: 16.169831486957175\n",
      "Iterations: 7200, Total iterations: 7200, Average batch training loss: 16.131223796606065\n",
      "Iterations: 7300, Total iterations: 7300, Average batch training loss: 16.080326348984077\n",
      "Iterations: 7400, Total iterations: 7400, Average batch training loss: 16.030339458375362\n",
      "Iterations: 7500, Total iterations: 7500, Average batch training loss: 16.000748639043174\n",
      "Iterations: 7600, Total iterations: 7600, Average batch training loss: 15.969139783445158\n",
      "Iterations: 7700, Total iterations: 7700, Average batch training loss: 15.92940245287759\n",
      "Iterations: 7800, Total iterations: 7800, Average batch training loss: 15.884061770133483\n",
      "Iterations: 7900, Total iterations: 7900, Average batch training loss: 15.84411275622211\n",
      "Iterations: 8000, Total iterations: 8000, Average batch training loss: 15.80610421949625\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 8000: Average validation loss = 3.9717665314674377\n",
      "Iteration 8000: Average validation metric = 6.242830455303192\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 8100, Total iterations: 8100, Average batch training loss: 15.75775696389469\n",
      "Iterations: 8200, Total iterations: 8200, Average batch training loss: 15.710982593268882\n",
      "Iterations: 8300, Total iterations: 8300, Average batch training loss: 15.684791199442852\n",
      "Iterations: 8400, Total iterations: 8400, Average batch training loss: 15.647276195798602\n",
      "Iterations: 8500, Total iterations: 8500, Average batch training loss: 15.607068815792308\n",
      "Iterations: 8600, Total iterations: 8600, Average batch training loss: 15.568123064262922\n",
      "Iterations: 8700, Total iterations: 8700, Average batch training loss: 15.533863389683866\n",
      "Iterations: 8800, Total iterations: 8800, Average batch training loss: 15.495130037177693\n",
      "Iterations: 8900, Total iterations: 8900, Average batch training loss: 15.4587302437793\n",
      "Iterations: 9000, Total iterations: 9000, Average batch training loss: 15.428203418678708\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 9000: Average validation loss = 3.82013176381588\n",
      "Iteration 9000: Average validation metric = 6.008904255926609\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 9100, Total iterations: 9100, Average batch training loss: 15.394900683361096\n",
      "Iterations: 9200, Total iterations: 9200, Average batch training loss: 15.36351299431013\n",
      "Iterations: 9300, Total iterations: 9300, Average batch training loss: 15.33075520664133\n",
      "Iterations: 9400, Total iterations: 9400, Average batch training loss: 15.28897615031993\n",
      "Iterations: 9500, Total iterations: 9500, Average batch training loss: 15.255702037309346\n",
      "Iterations: 9600, Total iterations: 9600, Average batch training loss: 15.218392319232226\n",
      "Iterations: 9700, Total iterations: 9700, Average batch training loss: 15.187656706977137\n",
      "Iterations: 9800, Total iterations: 9800, Average batch training loss: 15.155467306399832\n",
      "Iterations: 9900, Total iterations: 9900, Average batch training loss: 15.128181153644215\n",
      "Iterations: 10000, Total iterations: 10000, Average batch training loss: 15.097676230096816\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 10000: Average validation loss = 3.7929776292294264\n",
      "Iteration 10000: Average validation metric = 5.960523579269648\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 10100, Total iterations: 10100, Average batch training loss: 15.071645883239142\n",
      "Iterations: 10200, Total iterations: 10200, Average batch training loss: 15.043817125815972\n",
      "Iterations: 10300, Total iterations: 10300, Average batch training loss: 15.014006618157174\n",
      "Iterations: 10400, Total iterations: 10400, Average batch training loss: 14.988891438062375\n",
      "Iterations: 10500, Total iterations: 10500, Average batch training loss: 14.960924587204342\n",
      "Iterations: 10600, Total iterations: 10600, Average batch training loss: 14.924920921550607\n",
      "Iterations: 10700, Total iterations: 10700, Average batch training loss: 14.898544160985502\n",
      "Iterations: 10800, Total iterations: 10800, Average batch training loss: 14.872432039799513\n",
      "Iterations: 10900, Total iterations: 10900, Average batch training loss: 14.843256530717973\n",
      "Iterations: 11000, Total iterations: 11000, Average batch training loss: 14.811629270423543\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 11000: Average validation loss = 3.6124246064573526\n",
      "Iteration 11000: Average validation metric = 5.670244187116623\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 11100, Total iterations: 11100, Average batch training loss: 14.77986472198555\n",
      "Iterations: 11200, Total iterations: 11200, Average batch training loss: 14.744629160889557\n",
      "Iterations: 11300, Total iterations: 11300, Average batch training loss: 14.717726614876131\n",
      "Iterations: 11400, Total iterations: 11400, Average batch training loss: 14.696920188058886\n",
      "Iterations: 11500, Total iterations: 11500, Average batch training loss: 14.664581963414731\n",
      "Iterations: 11600, Total iterations: 11600, Average batch training loss: 14.631697572387498\n",
      "Iterations: 11700, Total iterations: 11700, Average batch training loss: 14.603257750486716\n",
      "Iterations: 11800, Total iterations: 11800, Average batch training loss: 14.578358717126362\n",
      "Iterations: 11900, Total iterations: 11900, Average batch training loss: 14.55278161834268\n",
      "Iterations: 12000, Total iterations: 12000, Average batch training loss: 14.534760362943013\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 12000: Average validation loss = 3.528989562764764\n",
      "Iteration 12000: Average validation metric = 5.546317424625158\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 12100, Total iterations: 12100, Average batch training loss: 14.505418389217912\n",
      "Iterations: 12200, Total iterations: 12200, Average batch training loss: 14.482536606788635\n",
      "Iterations: 12300, Total iterations: 12300, Average batch training loss: 14.451748341932529\n",
      "Iterations: 12400, Total iterations: 12400, Average batch training loss: 14.427855835960758\n",
      "Iterations: 12500, Total iterations: 12500, Average batch training loss: 14.401040325469971\n",
      "Iterations: 12600, Total iterations: 12600, Average batch training loss: 14.37486643075943\n",
      "Iterations: 12700, Total iterations: 12700, Average batch training loss: 14.354850372291926\n",
      "Iterations: 12800, Total iterations: 12800, Average batch training loss: 14.332512588575483\n",
      "Iterations: 12900, Total iterations: 12900, Average batch training loss: 14.312775144577026\n",
      "Iterations: 13100, Total iterations: 13100, Average batch training loss: 14.26055248624496\n",
      "Iterations: 13200, Total iterations: 13200, Average batch training loss: 14.237865645849343\n",
      "Iterations: 13300, Total iterations: 13300, Average batch training loss: 14.216582685951003\n",
      "Iterations: 13400, Total iterations: 13400, Average batch training loss: 14.197833819780778\n",
      "Iterations: 13500, Total iterations: 13500, Average batch training loss: 14.177000304645961\n",
      "Iterations: 13600, Total iterations: 13600, Average batch training loss: 14.15540082310929\n",
      "Iterations: 13700, Total iterations: 13700, Average batch training loss: 14.131342583294332\n",
      "Iterations: 13800, Total iterations: 13800, Average batch training loss: 14.11132218008456\n",
      "Iterations: 13900, Total iterations: 13900, Average batch training loss: 14.089097955964451\n",
      "Iterations: 14000, Total iterations: 14000, Average batch training loss: 14.067216723952974\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 14000: Average validation loss = 3.2873354591429234\n",
      "Iteration 14000: Average validation metric = 5.168579149991274\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 14100, Total iterations: 14100, Average batch training loss: 14.049052735186638\n",
      "Iterations: 14200, Total iterations: 14200, Average batch training loss: 14.03044214557594\n",
      "Iterations: 14300, Total iterations: 14300, Average batch training loss: 14.00885806583858\n",
      "Iterations: 14400, Total iterations: 14400, Average batch training loss: 13.991288395358456\n",
      "Iterations: 14500, Total iterations: 14500, Average batch training loss: 13.97163608139959\n",
      "Iterations: 14600, Total iterations: 14600, Average batch training loss: 13.947306686492816\n",
      "Iterations: 14700, Total iterations: 14700, Average batch training loss: 13.931352204076287\n",
      "Iterations: 14800, Total iterations: 14800, Average batch training loss: 13.911814337904389\n",
      "Iterations: 14900, Total iterations: 14900, Average batch training loss: 13.88785635279329\n",
      "Iterations: 15000, Total iterations: 15000, Average batch training loss: 13.871720380655924\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 15000: Average validation loss = 3.3313570395112038\n",
      "Iteration 15000: Average validation metric = 5.234128713607788\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 15100, Total iterations: 15100, Average batch training loss: 13.853301566957638\n",
      "Iterations: 15200, Total iterations: 15200, Average batch training loss: 13.836368972031694\n",
      "Iterations: 15300, Total iterations: 15300, Average batch training loss: 13.817647187818888\n",
      "Iterations: 15400, Total iterations: 15400, Average batch training loss: 13.794285364120038\n",
      "Iterations: 15500, Total iterations: 15500, Average batch training loss: 13.773267855582699\n",
      "Iterations: 15600, Total iterations: 15600, Average batch training loss: 13.751673235618151\n",
      "Iterations: 15700, Total iterations: 15700, Average batch training loss: 13.732192338165964\n",
      "Iterations: 15800, Total iterations: 15800, Average batch training loss: 13.711477713132206\n",
      "Iterations: 15900, Total iterations: 15900, Average batch training loss: 13.6884619822892\n",
      "Iterations: 16000, Total iterations: 16000, Average batch training loss: 13.66491050478816\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 16000: Average validation loss = 3.1905835531651974\n",
      "Iteration 16000: Average validation metric = 5.012998811900616\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 16100, Total iterations: 16100, Average batch training loss: 13.647938852843291\n",
      "Iterations: 16200, Total iterations: 16200, Average batch training loss: 13.631446542474958\n",
      "Iterations: 16300, Total iterations: 16300, Average batch training loss: 13.612607271510399\n",
      "Iterations: 16400, Total iterations: 16400, Average batch training loss: 13.59721007384905\n",
      "Iterations: 16500, Total iterations: 16500, Average batch training loss: 13.579799165089925\n",
      "Iterations: 16600, Total iterations: 16600, Average batch training loss: 13.558459609861833\n",
      "Iterations: 16700, Total iterations: 16700, Average batch training loss: 13.545517574198946\n",
      "Iterations: 16800, Total iterations: 16800, Average batch training loss: 13.524554734641598\n",
      "Iterations: 16900, Total iterations: 16900, Average batch training loss: 13.509604495926016\n",
      "Iterations: 17000, Total iterations: 17000, Average batch training loss: 13.490066726810792\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 17000: Average validation loss = 3.0752883218228817\n",
      "Iteration 17000: Average validation metric = 4.828341856598854\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 17100, Total iterations: 17100, Average batch training loss: 13.469249682775018\n",
      "Iterations: 17200, Total iterations: 17200, Average batch training loss: 13.450987260688184\n",
      "Iterations: 17300, Total iterations: 17300, Average batch training loss: 13.433860920081939\n",
      "Iterations: 17400, Total iterations: 17400, Average batch training loss: 13.417921534393026\n",
      "Iterations: 17500, Total iterations: 17500, Average batch training loss: 13.402523187759945\n",
      "Iterations: 17600, Total iterations: 17600, Average batch training loss: 13.38591950431466\n",
      "Iterations: 17700, Total iterations: 17700, Average batch training loss: 13.36668251375694\n",
      "Iterations: 17800, Total iterations: 17800, Average batch training loss: 13.351315658588089\n",
      "Iterations: 17900, Total iterations: 17900, Average batch training loss: 13.331831580367169\n",
      "Iterations: 18000, Total iterations: 18000, Average batch training loss: 13.318433423346944\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 18000: Average validation loss = 2.9480396527796984\n",
      "Iteration 18000: Average validation metric = 4.627030186355114\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 18100, Total iterations: 18100, Average batch training loss: 13.303916628360748\n",
      "Iterations: 18200, Total iterations: 18200, Average batch training loss: 13.287954230216833\n",
      "Iterations: 18300, Total iterations: 18300, Average batch training loss: 13.271620368032508\n",
      "Iterations: 18400, Total iterations: 18400, Average batch training loss: 13.25297904998064\n",
      "Iterations: 18500, Total iterations: 18500, Average batch training loss: 13.23226461705646\n",
      "Iterations: 18600, Total iterations: 18600, Average batch training loss: 13.222263089546594\n",
      "Iterations: 18700, Total iterations: 18700, Average batch training loss: 13.20455852950958\n",
      "Iterations: 18800, Total iterations: 18800, Average batch training loss: 13.185433603537843\n",
      "Iterations: 18900, Total iterations: 18900, Average batch training loss: 13.169090580624879\n",
      "Iterations: 19000, Total iterations: 19000, Average batch training loss: 13.150587313087364\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 19000: Average validation loss = 2.954381186515093\n",
      "Iteration 19000: Average validation metric = 4.642748631536961\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 19100, Total iterations: 19100, Average batch training loss: 13.135628091215462\n",
      "Iterations: 19200, Total iterations: 19200, Average batch training loss: 13.121676790975034\n",
      "Iterations: 19300, Total iterations: 19300, Average batch training loss: 13.107333510687932\n",
      "Iterations: 19400, Total iterations: 19400, Average batch training loss: 13.091376294782481\n",
      "Iterations: 19500, Total iterations: 19500, Average batch training loss: 13.07576622872475\n",
      "Iterations: 19600, Total iterations: 19600, Average batch training loss: 13.061378203606118\n",
      "Iterations: 19700, Total iterations: 19700, Average batch training loss: 13.046601703469523\n",
      "Iterations: 19800, Total iterations: 19800, Average batch training loss: 13.028714744900212\n",
      "Iterations: 19900, Total iterations: 19900, Average batch training loss: 13.012760904003029\n",
      "Iterations: 20000, Total iterations: 20000, Average batch training loss: 12.998729395592212\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 20000: Average validation loss = 2.935654904693365\n",
      "Iteration 20000: Average validation metric = 4.617220874875784\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 20100, Total iterations: 20100, Average batch training loss: 12.981177746941201\n",
      "Iterations: 20200, Total iterations: 20200, Average batch training loss: 12.96671976331437\n",
      "Iterations: 20300, Total iterations: 20300, Average batch training loss: 12.950798448517991\n",
      "Iterations: 20400, Total iterations: 20400, Average batch training loss: 12.930651632851246\n",
      "Iterations: 20500, Total iterations: 20500, Average batch training loss: 12.91467940643357\n",
      "Iterations: 20600, Total iterations: 20600, Average batch training loss: 12.899191749408407\n",
      "Iterations: 20700, Total iterations: 20700, Average batch training loss: 12.88363190310013\n",
      "Iterations: 20800, Total iterations: 20800, Average batch training loss: 12.868945561188918\n",
      "Iterations: 20900, Total iterations: 20900, Average batch training loss: 12.855596803774674\n",
      "Iterations: 21000, Total iterations: 21000, Average batch training loss: 12.837289467277982\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 21000: Average validation loss = 2.7667966708540916\n",
      "Iteration 21000: Average validation metric = 4.347039172425866\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 21100, Total iterations: 21100, Average batch training loss: 12.820672292223474\n",
      "Iterations: 21200, Total iterations: 21200, Average batch training loss: 12.806093603451297\n",
      "Iterations: 21300, Total iterations: 21300, Average batch training loss: 12.790991998334446\n",
      "Iterations: 21400, Total iterations: 21400, Average batch training loss: 12.779137473050678\n",
      "Iterations: 21600, Total iterations: 21600, Average batch training loss: 12.748957234102267\n",
      "Iterations: 21700, Total iterations: 21700, Average batch training loss: 12.732046167081402\n",
      "Iterations: 21800, Total iterations: 21800, Average batch training loss: 12.717650364517072\n",
      "Iterations: 21900, Total iterations: 21900, Average batch training loss: 12.702145426828567\n",
      "Iterations: 22000, Total iterations: 22000, Average batch training loss: 12.690283022848043\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 22000: Average validation loss = 2.6851494144648314\n",
      "Iteration 22000: Average validation metric = 4.219918172806501\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 22100, Total iterations: 22100, Average batch training loss: 12.676638226584611\n",
      "Iterations: 22200, Total iterations: 22200, Average batch training loss: 12.6641079668204\n",
      "Iterations: 22300, Total iterations: 22300, Average batch training loss: 12.650721926763987\n",
      "Iterations: 22400, Total iterations: 22400, Average batch training loss: 12.637693836891225\n",
      "Iterations: 22500, Total iterations: 22500, Average batch training loss: 12.626123493014441\n",
      "Iterations: 22600, Total iterations: 22600, Average batch training loss: 12.6130790746423\n",
      "Iterations: 22700, Total iterations: 22700, Average batch training loss: 12.598222602810628\n",
      "Iterations: 22800, Total iterations: 22800, Average batch training loss: 12.583533208485235\n",
      "Iterations: 22900, Total iterations: 22900, Average batch training loss: 12.56900560747588\n",
      "Iterations: 23000, Total iterations: 23000, Average batch training loss: 12.553916437739911\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 23000: Average validation loss = 2.5764414109289646\n",
      "Iteration 23000: Average validation metric = 4.051891252398491\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 23100, Total iterations: 23100, Average batch training loss: 12.539424065614675\n",
      "Iterations: 23200, Total iterations: 23200, Average batch training loss: 12.52475947090264\n",
      "Iterations: 23300, Total iterations: 23300, Average batch training loss: 12.509067340470178\n",
      "Iterations: 23400, Total iterations: 23400, Average batch training loss: 12.49606120537489\n",
      "Iterations: 23500, Total iterations: 23500, Average batch training loss: 12.480575534191537\n",
      "Iterations: 23600, Total iterations: 23600, Average batch training loss: 12.466856970180899\n",
      "Iterations: 23700, Total iterations: 23700, Average batch training loss: 12.451703866825827\n",
      "Iterations: 23800, Total iterations: 23800, Average batch training loss: 12.438571274500935\n",
      "Iterations: 23900, Total iterations: 23900, Average batch training loss: 12.424588611135922\n",
      "Iterations: 24000, Total iterations: 24000, Average batch training loss: 12.412610219736894\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 24000: Average validation loss = 2.596338214352727\n",
      "Iteration 24000: Average validation metric = 4.095601014792919\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 24100, Total iterations: 24100, Average batch training loss: 12.39877752337713\n",
      "Iterations: 24200, Total iterations: 24200, Average batch training loss: 12.385387281701584\n",
      "Iterations: 24300, Total iterations: 24300, Average batch training loss: 12.372956206435529\n",
      "Iterations: 24400, Total iterations: 24400, Average batch training loss: 12.358665073054736\n",
      "Iterations: 24500, Total iterations: 24500, Average batch training loss: 12.344668030008977\n",
      "Iterations: 24600, Total iterations: 24600, Average batch training loss: 12.329347616308103\n",
      "Iterations: 24700, Total iterations: 24700, Average batch training loss: 12.317549379113233\n",
      "Iterations: 24800, Total iterations: 24800, Average batch training loss: 12.304333872343264\n",
      "Iterations: 24900, Total iterations: 24900, Average batch training loss: 12.290229976177216\n",
      "Iterations: 25000, Total iterations: 25000, Average batch training loss: 12.274212216882706\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 25000: Average validation loss = 2.5334249939769506\n",
      "Iteration 25000: Average validation metric = 3.9793359637260437\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 25100, Total iterations: 25100, Average batch training loss: 12.263110807606898\n",
      "Iterations: 25200, Total iterations: 25200, Average batch training loss: 12.25054053184532\n",
      "Iterations: 25300, Total iterations: 25300, Average batch training loss: 12.235494095600641\n",
      "Iterations: 25400, Total iterations: 25400, Average batch training loss: 12.223161676474444\n",
      "Iterations: 25500, Total iterations: 25500, Average batch training loss: 12.21269082480786\n",
      "Iterations: 25600, Total iterations: 25600, Average batch training loss: 12.202319144904614\n",
      "Iterations: 25700, Total iterations: 25700, Average batch training loss: 12.19006979855118\n",
      "Iterations: 25800, Total iterations: 25800, Average batch training loss: 12.176521753497825\n",
      "Iterations: 25900, Total iterations: 25900, Average batch training loss: 12.165186349553952\n",
      "Iterations: 26000, Total iterations: 26000, Average batch training loss: 12.152836939839217\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 26000: Average validation loss = 2.469981910660863\n",
      "Iteration 26000: Average validation metric = 3.8868295587599277\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 26100, Total iterations: 26100, Average batch training loss: 12.141074564073278\n",
      "Iterations: 26200, Total iterations: 26200, Average batch training loss: 12.128999276070195\n",
      "Iterations: 26300, Total iterations: 26300, Average batch training loss: 12.117074398686224\n",
      "Iterations: 26400, Total iterations: 26400, Average batch training loss: 12.105518947108225\n",
      "Iterations: 26500, Total iterations: 26500, Average batch training loss: 12.092953467360083\n",
      "Iterations: 26600, Total iterations: 26600, Average batch training loss: 12.079742290910922\n",
      "Iterations: 26700, Total iterations: 26700, Average batch training loss: 12.06617658641008\n",
      "Iterations: 26800, Total iterations: 26800, Average batch training loss: 12.055219811761557\n",
      "Iterations: 26900, Total iterations: 26900, Average batch training loss: 12.0447013066072\n",
      "Iterations: 27000, Total iterations: 27000, Average batch training loss: 12.035358791501434\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 27000: Average validation loss = 2.4245633389800787\n",
      "Iteration 27000: Average validation metric = 3.8031722474843264\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 27100, Total iterations: 27100, Average batch training loss: 12.022653633501257\n",
      "Iterations: 27200, Total iterations: 27200, Average batch training loss: 12.01087894588709\n",
      "Iterations: 27300, Total iterations: 27300, Average batch training loss: 11.998940527674916\n",
      "Iterations: 27400, Total iterations: 27400, Average batch training loss: 11.984993654332891\n",
      "Iterations: 27500, Total iterations: 27500, Average batch training loss: 11.975365096308968\n",
      "Iterations: 27600, Total iterations: 27600, Average batch training loss: 11.963093533023544\n",
      "Iterations: 27700, Total iterations: 27700, Average batch training loss: 11.949915618337018\n",
      "Iterations: 27800, Total iterations: 27800, Average batch training loss: 11.937637927369249\n",
      "Iterations: 27900, Total iterations: 27900, Average batch training loss: 11.926367068905984\n",
      "Iterations: 28000, Total iterations: 28000, Average batch training loss: 11.915355401439326\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 28000: Average validation loss = 2.4044534284621477\n",
      "Iteration 28000: Average validation metric = 3.782222919166088\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 28100, Total iterations: 28100, Average batch training loss: 11.903040623673341\n",
      "Iterations: 28200, Total iterations: 28200, Average batch training loss: 11.889892427955113\n",
      "Iterations: 28300, Total iterations: 28300, Average batch training loss: 11.87903911392596\n",
      "Iterations: 28400, Total iterations: 28400, Average batch training loss: 11.867207665628111\n",
      "Iterations: 28500, Total iterations: 28500, Average batch training loss: 11.856207490862461\n",
      "Iterations: 28600, Total iterations: 28600, Average batch training loss: 11.845327535876027\n",
      "Iterations: 28700, Total iterations: 28700, Average batch training loss: 11.83302432792112\n",
      "Iterations: 28800, Total iterations: 28800, Average batch training loss: 11.822608849546976\n",
      "Iterations: 28900, Total iterations: 28900, Average batch training loss: 11.811228740396796\n",
      "Iterations: 29000, Total iterations: 29000, Average batch training loss: 11.799319043159485\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 29000: Average validation loss = 2.359023926779628\n",
      "Iteration 29000: Average validation metric = 3.712418269366026\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 29100, Total iterations: 29100, Average batch training loss: 11.78912182059075\n",
      "Iterations: 29200, Total iterations: 29200, Average batch training loss: 11.77753797939379\n",
      "Iterations: 29300, Total iterations: 29300, Average batch training loss: 11.764396844829715\n",
      "Iterations: 29400, Total iterations: 29400, Average batch training loss: 11.753880867901303\n",
      "Iterations: 29500, Total iterations: 29500, Average batch training loss: 11.743469887741542\n",
      "Iterations: 29600, Total iterations: 29600, Average batch training loss: 11.732109213858037\n",
      "Iterations: 29700, Total iterations: 29700, Average batch training loss: 11.72257701595223\n",
      "Iterations: 29800, Total iterations: 29800, Average batch training loss: 11.712995354433188\n",
      "Iterations: 29900, Total iterations: 29900, Average batch training loss: 11.700516024839917\n",
      "Iterations: 30000, Total iterations: 30000, Average batch training loss: 11.691465719850859\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 30000: Average validation loss = 2.2834507524967194\n",
      "Iteration 30000: Average validation metric = 3.585509480908513\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 30100, Total iterations: 30100, Average batch training loss: 11.681423992136388\n",
      "Iterations: 30200, Total iterations: 30200, Average batch training loss: 11.669749130026394\n",
      "Iterations: 30300, Total iterations: 30300, Average batch training loss: 11.65874091516627\n",
      "Iterations: 30400, Total iterations: 30400, Average batch training loss: 11.648730094903394\n",
      "Iterations: 30500, Total iterations: 30500, Average batch training loss: 11.63759356921618\n",
      "Iterations: 30600, Total iterations: 30600, Average batch training loss: 11.624779455926683\n",
      "Iterations: 30700, Total iterations: 30700, Average batch training loss: 11.616272354840456\n",
      "Iterations: 30800, Total iterations: 30800, Average batch training loss: 11.606304128200977\n",
      "Iterations: 30900, Total iterations: 30900, Average batch training loss: 11.594598306012385\n",
      "Iterations: 31000, Total iterations: 31000, Average batch training loss: 11.582823360704607\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 31000: Average validation loss = 2.355957593768835\n",
      "Iteration 31000: Average validation metric = 3.6983743347227573\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 31100, Total iterations: 31100, Average batch training loss: 11.575346368562753\n",
      "Iterations: 31200, Total iterations: 31200, Average batch training loss: 11.565306517588787\n",
      "Iterations: 31300, Total iterations: 31300, Average batch training loss: 11.557071528480456\n",
      "Iterations: 31400, Total iterations: 31400, Average batch training loss: 11.547297023041233\n",
      "Iterations: 31500, Total iterations: 31500, Average batch training loss: 11.536414836179642\n",
      "Iterations: 31600, Total iterations: 31600, Average batch training loss: 11.524871538643595\n",
      "Iterations: 31700, Total iterations: 31700, Average batch training loss: 11.514090371868964\n",
      "Iterations: 31800, Total iterations: 31800, Average batch training loss: 11.50336784479753\n",
      "Iterations: 31900, Total iterations: 31900, Average batch training loss: 11.492353639273809\n",
      "Iterations: 32000, Total iterations: 32000, Average batch training loss: 11.482722622402012\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 32000: Average validation loss = 2.2509160973131657\n",
      "Iteration 32000: Average validation metric = 3.5349681563675404\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 32100, Total iterations: 32100, Average batch training loss: 11.472807521671522\n",
      "Iterations: 32200, Total iterations: 32200, Average batch training loss: 11.463081688540322\n",
      "Iterations: 32300, Total iterations: 32300, Average batch training loss: 11.45473574484834\n",
      "Iterations: 32400, Total iterations: 32400, Average batch training loss: 11.445972541732553\n",
      "Iterations: 32500, Total iterations: 32500, Average batch training loss: 11.434871780564235\n",
      "Iterations: 32600, Total iterations: 32600, Average batch training loss: 11.423941601193023\n",
      "Iterations: 32700, Total iterations: 32700, Average batch training loss: 11.41226559155578\n",
      "Iterations: 32800, Total iterations: 32800, Average batch training loss: 11.401106465386182\n",
      "Iterations: 32900, Total iterations: 32900, Average batch training loss: 11.391528206183192\n",
      "Iterations: 33000, Total iterations: 33000, Average batch training loss: 11.381660605784619\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 33000: Average validation loss = 2.2443683072924614\n",
      "Iteration 33000: Average validation metric = 3.5296373534947634\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 33100, Total iterations: 33100, Average batch training loss: 11.37108258013999\n",
      "Iterations: 33200, Total iterations: 33200, Average batch training loss: 11.361843843201557\n",
      "Iterations: 33300, Total iterations: 33300, Average batch training loss: 11.351240686346461\n",
      "Iterations: 33400, Total iterations: 33400, Average batch training loss: 11.342451006630938\n",
      "Iterations: 33500, Total iterations: 33500, Average batch training loss: 11.332933256028303\n",
      "Iterations: 33600, Total iterations: 33600, Average batch training loss: 11.32443722056491\n",
      "Iterations: 33700, Total iterations: 33700, Average batch training loss: 11.315547063230406\n",
      "Iterations: 33800, Total iterations: 33800, Average batch training loss: 11.30508941916319\n",
      "Iterations: 33900, Total iterations: 33900, Average batch training loss: 11.296041090945579\n",
      "Iterations: 34000, Total iterations: 34000, Average batch training loss: 11.286759697493386\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 34000: Average validation loss = 2.180814726278186\n",
      "Iteration 34000: Average validation metric = 3.427574973553419\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 34100, Total iterations: 34100, Average batch training loss: 11.276062266407125\n",
      "Iterations: 34200, Total iterations: 34200, Average batch training loss: 11.265544826921664\n",
      "Iterations: 34300, Total iterations: 34300, Average batch training loss: 11.257922568912061\n",
      "Iterations: 34400, Total iterations: 34400, Average batch training loss: 11.246944981473822\n",
      "Iterations: 34500, Total iterations: 34500, Average batch training loss: 11.237785417888475\n",
      "Iterations: 34600, Total iterations: 34600, Average batch training loss: 11.228096181312738\n",
      "Iterations: 34700, Total iterations: 34700, Average batch training loss: 11.217738453984603\n",
      "Iterations: 34800, Total iterations: 34800, Average batch training loss: 11.208794092172864\n",
      "Iterations: 34900, Total iterations: 34900, Average batch training loss: 11.200681694804086\n",
      "Iterations: 35000, Total iterations: 35000, Average batch training loss: 11.19332497976848\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 35000: Average validation loss = 2.208274209871888\n",
      "Iteration 35000: Average validation metric = 3.470855688676238\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 35100, Total iterations: 35100, Average batch training loss: 11.18330924280009\n",
      "Iterations: 35200, Total iterations: 35200, Average batch training loss: 11.17525369523601\n",
      "Iterations: 35300, Total iterations: 35300, Average batch training loss: 11.166467186492833\n",
      "Iterations: 35400, Total iterations: 35400, Average batch training loss: 11.157558645683494\n",
      "Iterations: 35500, Total iterations: 35500, Average batch training loss: 11.148108074067345\n",
      "Iterations: 35600, Total iterations: 35600, Average batch training loss: 11.138055044479584\n",
      "Iterations: 35700, Total iterations: 35700, Average batch training loss: 11.131951275512952\n",
      "Iterations: 35800, Total iterations: 35800, Average batch training loss: 11.124687336356946\n",
      "Iterations: 35900, Total iterations: 35900, Average batch training loss: 11.116641704219298\n",
      "Iterations: 36000, Total iterations: 36000, Average batch training loss: 11.10834213003185\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 36000: Average validation loss = 2.2336226496845484\n",
      "Iteration 36000: Average validation metric = 3.51421245187521\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 36100, Total iterations: 36100, Average batch training loss: 11.098748108680228\n",
      "Iterations: 36200, Total iterations: 36200, Average batch training loss: 11.090365961618845\n",
      "Iterations: 36300, Total iterations: 36300, Average batch training loss: 11.081594098330202\n",
      "Iterations: 36400, Total iterations: 36400, Average batch training loss: 11.07225260090697\n",
      "Iterations: 36500, Total iterations: 36500, Average batch training loss: 11.06480061823048\n",
      "Iterations: 36600, Total iterations: 36600, Average batch training loss: 11.0567385511711\n",
      "Iterations: 36700, Total iterations: 36700, Average batch training loss: 11.047766992915879\n",
      "Iterations: 36800, Total iterations: 36800, Average batch training loss: 11.040039796304443\n",
      "Iterations: 36900, Total iterations: 36900, Average batch training loss: 11.03222278554265\n",
      "Iterations: 37000, Total iterations: 37000, Average batch training loss: 11.024431555561117\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 37000: Average validation loss = 2.1462048552930355\n",
      "Iteration 37000: Average validation metric = 3.367546234279871\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 37100, Total iterations: 37100, Average batch training loss: 11.015310260150631\n",
      "Iterations: 37200, Total iterations: 37200, Average batch training loss: 11.008342440660282\n",
      "Iterations: 37300, Total iterations: 37300, Average batch training loss: 10.999713907152334\n",
      "Iterations: 37400, Total iterations: 37400, Average batch training loss: 10.991205331259232\n",
      "Iterations: 37500, Total iterations: 37500, Average batch training loss: 10.982880575154622\n",
      "Iterations: 37600, Total iterations: 37600, Average batch training loss: 10.973283946412675\n",
      "Iterations: 37700, Total iterations: 37700, Average batch training loss: 10.962260118985366\n",
      "Iterations: 37800, Total iterations: 37800, Average batch training loss: 10.952396166463378\n",
      "Iterations: 37900, Total iterations: 37900, Average batch training loss: 10.943079546183583\n",
      "Iterations: 38000, Total iterations: 38000, Average batch training loss: 10.93552720406181\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 38000: Average validation loss = 2.097535412758589\n",
      "Iteration 38000: Average validation metric = 3.2911895252764225\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 38100, Total iterations: 38100, Average batch training loss: 10.926923687576934\n",
      "Iterations: 38200, Total iterations: 38200, Average batch training loss: 10.918510630124526\n",
      "Iterations: 38300, Total iterations: 38300, Average batch training loss: 10.910510226565926\n",
      "Iterations: 38400, Total iterations: 38400, Average batch training loss: 10.901460756709179\n",
      "Iterations: 38500, Total iterations: 38500, Average batch training loss: 10.89344340285388\n",
      "Iterations: 38600, Total iterations: 38600, Average batch training loss: 10.88621297955513\n",
      "Iterations: 38700, Total iterations: 38700, Average batch training loss: 10.878079549453055\n",
      "Iterations: 38800, Total iterations: 38800, Average batch training loss: 10.870260957663822\n",
      "Iterations: 38900, Total iterations: 38900, Average batch training loss: 10.862975743748535\n",
      "Iterations: 39000, Total iterations: 39000, Average batch training loss: 10.854089828411738\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 39000: Average validation loss = 2.1119489204138517\n",
      "Iteration 39000: Average validation metric = 3.322532970458269\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 39100, Total iterations: 39100, Average batch training loss: 10.845286956376126\n",
      "Iterations: 39200, Total iterations: 39200, Average batch training loss: 10.836031712579484\n",
      "Iterations: 39300, Total iterations: 39300, Average batch training loss: 10.827381662843186\n",
      "Iterations: 39400, Total iterations: 39400, Average batch training loss: 10.819347509375683\n",
      "Iterations: 39500, Total iterations: 39500, Average batch training loss: 10.811247109419183\n",
      "Iterations: 39600, Total iterations: 39600, Average batch training loss: 10.804395407426236\n",
      "Iterations: 39700, Total iterations: 39700, Average batch training loss: 10.79736939798975\n",
      "Iterations: 39800, Total iterations: 39800, Average batch training loss: 10.788492353154187\n",
      "Iterations: 39900, Total iterations: 39900, Average batch training loss: 10.781563169400496\n",
      "Iterations: 40000, Total iterations: 40000, Average batch training loss: 10.772728305000067\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 40000: Average validation loss = 2.109345408156514\n",
      "Iteration 40000: Average validation metric = 3.321419356390834\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 40100, Total iterations: 40100, Average batch training loss: 10.764693894540876\n",
      "Iterations: 40200, Total iterations: 40200, Average batch training loss: 10.75718750000593\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2c858-a78b-42be-befe-8d8a2257df21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Training output 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2351603-bdbd-4604-b5c1-6a60c3cdc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: SequenceLoss is initialized!\n",
      "Optimizer: AdamW is initialized!\n",
      "Scheduler: OneCycleLR is initialized!\n",
      "Training config:\n",
      "\n",
      "CKPT_DIR: ../../results/crossflow/ckpts/exp002\n",
      "CKPT_INTERVAL: 20000\n",
      "CRITERION:\n",
      "  CUSTOM: True\n",
      "  NAME: SequenceLoss\n",
      "  PARAMS:\n",
      "    gamma: 0.8\n",
      "    max_flow: 400.0\n",
      "DATA:\n",
      "  APPEND_VALID_MASK: True\n",
      "  AUGMENTATION:\n",
      "    PARAMS:\n",
      "      TRAINING:\n",
      "        AUTOFLOW_SPATIAL_PARAMS:\n",
      "          black: False\n",
      "          enabled: False\n",
      "          rot: [0.4, 0.03]\n",
      "          scale: [0.3, 0.03, 0.1]\n",
      "          squeeze: [0.3, 0.0]\n",
      "          trans: [0.4, 0.03]\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.2\n",
      "          brightness: 0.4\n",
      "          contrast: 0.4\n",
      "          enabled: True\n",
      "          hue: 0.15915494309189535\n",
      "          saturation: 0.4\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          bounds: [50, 100]\n",
      "          enabled: True\n",
      "        NOISE_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          enabled: False\n",
      "          noise_std_range: 0.06\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.8\n",
      "          enabled: True\n",
      "          flip: True\n",
      "          h_flip_prob: 0.5\n",
      "          max_scale: 1.0\n",
      "          max_stretch: 0.2\n",
      "          min_scale: -0.1\n",
      "          stretch_prob: 0.8\n",
      "          v_flip_prob: 0.1\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "      VALIDATION:\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "    USE: True\n",
      "  BATCH_SIZE: 10\n",
      "  NORM_PARAMS:\n",
      "    mean: [0.485, 0.456, 0.406]\n",
      "    std: [0.229, 0.224, 0.225]\n",
      "    use: True\n",
      "  NUM_WORKERS: 4\n",
      "  PIN_MEMORY: True\n",
      "  SHUFFLE: True\n",
      "  TRAIN_CROP_SIZE: [384, 512]\n",
      "  TRAIN_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "  VAL_CROP_SIZE: [384, 512]\n",
      "  VAL_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "DEVICE: 0\n",
      "DISTRIBUTED:\n",
      "  BACKEND: nccl\n",
      "  MASTER_ADDR: localhost\n",
      "  MASTER_PORT: 12355\n",
      "  SYNC_BATCH_NORM: True\n",
      "  USE: False\n",
      "  WORLD_SIZE: 4\n",
      "EPOCHS: None\n",
      "FREEZE_BATCH_NORM: False\n",
      "GRAD_CLIP:\n",
      "  USE: True\n",
      "  VALUE: 1.0\n",
      "LOG_DIR: ../../results/crossflow/logs/exp002\n",
      "LOG_ITERATIONS_INTERVAL: 100\n",
      "MIXED_PRECISION: False\n",
      "NUM_STEPS: 50000\n",
      "OPTIMIZER:\n",
      "  LR: 0.0004\n",
      "  NAME: AdamW\n",
      "  PARAMS:\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    eps: 1e-08\n",
      "    weight_decay: 0.0001\n",
      "RESUME_TRAINING:\n",
      "  CONSOLIDATED_CKPT: None\n",
      "  EPOCHS: 100\n",
      "  START_EPOCH: None\n",
      "SCHEDULER:\n",
      "  NAME: OneCycleLR\n",
      "  PARAMS:\n",
      "    anneal_strategy: linear\n",
      "    cycle_momentum: False\n",
      "    max_lr: 0.0004\n",
      "    pct_start: 0.05\n",
      "    total_steps: 50100\n",
      "  USE: True\n",
      "TARGET_SCALE_FACTOR: 1.0\n",
      "VALIDATE_INTERVAL: 1000\n",
      "VALIDATE_ON: metric\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Starting step 1 of 50001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/nnflow-0.0.0-py3.7.egg/nnflow/models/gmflow/position.py:39: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811797118/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 100, Total iterations: 100, Average batch training loss: 47.402778425216674\n",
      "Iterations: 200, Total iterations: 200, Average batch training loss: 34.730524196624756\n",
      "Iterations: 300, Total iterations: 300, Average batch training loss: 30.00316294034322\n",
      "Iterations: 400, Total iterations: 400, Average batch training loss: 27.572381217479705\n",
      "Iterations: 500, Total iterations: 500, Average batch training loss: 25.961023359298707\n",
      "Iterations: 600, Total iterations: 600, Average batch training loss: 24.760241158803304\n",
      "Iterations: 700, Total iterations: 700, Average batch training loss: 23.832342450278144\n",
      "Iterations: 800, Total iterations: 800, Average batch training loss: 23.23447922706604\n",
      "Iterations: 900, Total iterations: 900, Average batch training loss: 22.79281840854221\n",
      "Iterations: 1000, Total iterations: 1000, Average batch training loss: 22.250091296195983\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1000: Average validation loss = 7.223035506904125\n",
      "Iteration 1000: Average validation metric = 11.235714755952358\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 1100, Total iterations: 1100, Average batch training loss: 21.830688512108544\n",
      "Iterations: 1200, Total iterations: 1200, Average batch training loss: 21.64697078704834\n",
      "Iterations: 1300, Total iterations: 1300, Average batch training loss: 21.384069350315976\n",
      "Iterations: 1400, Total iterations: 1400, Average batch training loss: 21.181176603862216\n",
      "Iterations: 1500, Total iterations: 1500, Average batch training loss: 20.966571857452394\n",
      "Iterations: 1600, Total iterations: 1600, Average batch training loss: 20.79018246114254\n",
      "Iterations: 1700, Total iterations: 1700, Average batch training loss: 20.568236613554113\n",
      "Iterations: 1800, Total iterations: 1800, Average batch training loss: 20.436887958314685\n",
      "Iterations: 1900, Total iterations: 1900, Average batch training loss: 20.311416050760368\n",
      "Iterations: 2000, Total iterations: 2000, Average batch training loss: 20.205334182739257\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2000: Average validation loss = 6.72199247777462\n",
      "Iteration 2000: Average validation metric = 10.49899124354124\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 2100, Total iterations: 2100, Average batch training loss: 20.097667285374232\n",
      "Iterations: 2200, Total iterations: 2200, Average batch training loss: 19.947752112475307\n",
      "Iterations: 2300, Total iterations: 2300, Average batch training loss: 19.80791133383046\n",
      "Iterations: 2400, Total iterations: 2400, Average batch training loss: 19.706062490145367\n",
      "Iterations: 2500, Total iterations: 2500, Average batch training loss: 19.61894928588867\n",
      "Iterations: 2600, Total iterations: 2600, Average batch training loss: 19.508825229864854\n",
      "Iterations: 2700, Total iterations: 2700, Average batch training loss: 19.380503635406495\n",
      "Iterations: 2800, Total iterations: 2800, Average batch training loss: 19.299366248505457\n",
      "Iterations: 2900, Total iterations: 2900, Average batch training loss: 19.21871565605032\n",
      "Iterations: 3000, Total iterations: 3000, Average batch training loss: 19.10619175640742\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3000: Average validation loss = 5.797550190240145\n",
      "Iteration 3000: Average validation metric = 9.099431477487087\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 3100, Total iterations: 3100, Average batch training loss: 18.99899295483866\n",
      "Iterations: 3200, Total iterations: 3200, Average batch training loss: 18.899886110275983\n",
      "Iterations: 3300, Total iterations: 3300, Average batch training loss: 18.808632295348428\n",
      "Iterations: 3400, Total iterations: 3400, Average batch training loss: 18.69942023038864\n",
      "Iterations: 3500, Total iterations: 3500, Average batch training loss: 18.60217417049408\n",
      "Iterations: 3600, Total iterations: 3600, Average batch training loss: 18.485639276372062\n",
      "Iterations: 3700, Total iterations: 3700, Average batch training loss: 18.38455101889533\n",
      "Iterations: 3800, Total iterations: 3800, Average batch training loss: 18.28440254838843\n",
      "Iterations: 3900, Total iterations: 3900, Average batch training loss: 18.203646390132416\n",
      "Iterations: 4000, Total iterations: 4000, Average batch training loss: 18.113248947143553\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4000: Average validation loss = 5.026309542357922\n",
      "Iteration 4000: Average validation metric = 7.905326906591654\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 4100, Total iterations: 4100, Average batch training loss: 18.026260912243913\n",
      "Iterations: 4200, Total iterations: 4200, Average batch training loss: 17.94592650697345\n",
      "Iterations: 4300, Total iterations: 4300, Average batch training loss: 17.860833561475886\n",
      "Iterations: 4400, Total iterations: 4400, Average batch training loss: 17.785012500936336\n",
      "Iterations: 4500, Total iterations: 4500, Average batch training loss: 17.705490291701423\n",
      "Iterations: 4600, Total iterations: 4600, Average batch training loss: 17.65217920396639\n",
      "Iterations: 4700, Total iterations: 4700, Average batch training loss: 17.567838197667548\n",
      "Iterations: 4800, Total iterations: 4800, Average batch training loss: 17.49060883114735\n",
      "Iterations: 4900, Total iterations: 4900, Average batch training loss: 17.418056893056754\n",
      "Iterations: 5000, Total iterations: 5000, Average batch training loss: 17.357766950416565\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5000: Average validation loss = 4.720407173037529\n",
      "Iteration 5000: Average validation metric = 7.424663219600916\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 5100, Total iterations: 5100, Average batch training loss: 17.292748564551857\n",
      "Iterations: 5200, Total iterations: 5200, Average batch training loss: 17.214361070394517\n",
      "Iterations: 5300, Total iterations: 5300, Average batch training loss: 17.150526305144687\n",
      "Iterations: 5400, Total iterations: 5400, Average batch training loss: 17.080030625661212\n",
      "Iterations: 5500, Total iterations: 5500, Average batch training loss: 17.00023891171542\n",
      "Iterations: 5600, Total iterations: 5600, Average batch training loss: 16.944741450633323\n",
      "Iterations: 5700, Total iterations: 5700, Average batch training loss: 16.882382456712556\n",
      "Iterations: 5800, Total iterations: 5800, Average batch training loss: 16.819720669861496\n",
      "Iterations: 5900, Total iterations: 5900, Average batch training loss: 16.76572695045148\n",
      "Iterations: 6000, Total iterations: 6000, Average batch training loss: 16.721437486330668\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6000: Average validation loss = 4.405416116118431\n",
      "Iteration 6000: Average validation metric = 6.920740939676762\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 6100, Total iterations: 6100, Average batch training loss: 16.67204614084275\n",
      "Iterations: 6200, Total iterations: 6200, Average batch training loss: 16.609836340335107\n",
      "Iterations: 6300, Total iterations: 6300, Average batch training loss: 16.57660911204323\n",
      "Iterations: 6400, Total iterations: 6400, Average batch training loss: 16.5191481410712\n",
      "Iterations: 6500, Total iterations: 6500, Average batch training loss: 16.463480983073893\n",
      "Iterations: 6600, Total iterations: 6600, Average batch training loss: 16.410509131532727\n",
      "Iterations: 6700, Total iterations: 6700, Average batch training loss: 16.35164111358016\n",
      "Iterations: 6800, Total iterations: 6800, Average batch training loss: 16.292943728460987\n",
      "Iterations: 6900, Total iterations: 6900, Average batch training loss: 16.243643716245458\n",
      "Iterations: 7000, Total iterations: 7000, Average batch training loss: 16.189372710159848\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7000: Average validation loss = 4.137905955314636\n",
      "Iteration 7000: Average validation metric = 6.507737774401903\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 7100, Total iterations: 7100, Average batch training loss: 16.129782009259078\n",
      "Iterations: 7200, Total iterations: 7200, Average batch training loss: 16.081521723535324\n",
      "Iterations: 7300, Total iterations: 7300, Average batch training loss: 16.035277917548402\n",
      "Iterations: 7400, Total iterations: 7400, Average batch training loss: 15.995272082380346\n",
      "Iterations: 7500, Total iterations: 7500, Average batch training loss: 15.956046216964722\n",
      "Iterations: 7600, Total iterations: 7600, Average batch training loss: 15.92213094579546\n",
      "Iterations: 7700, Total iterations: 7700, Average batch training loss: 15.880642103281888\n",
      "Iterations: 7800, Total iterations: 7800, Average batch training loss: 15.828696652498001\n",
      "Iterations: 7900, Total iterations: 7900, Average batch training loss: 15.774921704545806\n",
      "Iterations: 8000, Total iterations: 8000, Average batch training loss: 15.73052045851946\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 8000: Average validation loss = 3.979580443352461\n",
      "Iteration 8000: Average validation metric = 6.267592038959265\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 8100, Total iterations: 8100, Average batch training loss: 15.684121308797671\n",
      "Iterations: 8200, Total iterations: 8200, Average batch training loss: 15.6403992148725\n",
      "Iterations: 8300, Total iterations: 8300, Average batch training loss: 15.602581559951046\n",
      "Iterations: 8400, Total iterations: 8400, Average batch training loss: 15.560220337992623\n",
      "Iterations: 8500, Total iterations: 8500, Average batch training loss: 15.523273923705606\n",
      "Iterations: 8600, Total iterations: 8600, Average batch training loss: 15.47881547395573\n",
      "Iterations: 8700, Total iterations: 8700, Average batch training loss: 15.43848512370011\n",
      "Iterations: 8800, Total iterations: 8800, Average batch training loss: 15.38990711228414\n",
      "Iterations: 8900, Total iterations: 8900, Average batch training loss: 15.351235412319054\n",
      "Iterations: 9000, Total iterations: 9000, Average batch training loss: 15.305094373808966\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 9000: Average validation loss = 3.8835595473647118\n",
      "Iteration 9000: Average validation metric = 6.1132475435733795\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 9100, Total iterations: 9100, Average batch training loss: 15.264275540414747\n",
      "Iterations: 9200, Total iterations: 9200, Average batch training loss: 15.226142690233562\n",
      "Iterations: 9300, Total iterations: 9300, Average batch training loss: 15.180276253454148\n",
      "Iterations: 9400, Total iterations: 9400, Average batch training loss: 15.137774898346434\n",
      "Iterations: 9500, Total iterations: 9500, Average batch training loss: 15.10092748275556\n",
      "Iterations: 9600, Total iterations: 9600, Average batch training loss: 15.067323458939791\n",
      "Iterations: 9700, Total iterations: 9700, Average batch training loss: 15.032188059226753\n",
      "Iterations: 9800, Total iterations: 9800, Average batch training loss: 14.998161426709622\n",
      "Iterations: 9900, Total iterations: 9900, Average batch training loss: 14.961048384049926\n",
      "Iterations: 11100, Total iterations: 11100, Average batch training loss: 14.582509921134056\n",
      "Iterations: 11200, Total iterations: 11200, Average batch training loss: 14.554214825928211\n",
      "Iterations: 11300, Total iterations: 11300, Average batch training loss: 14.526171953614835\n",
      "Iterations: 11400, Total iterations: 11400, Average batch training loss: 14.495332243986297\n",
      "Iterations: 11500, Total iterations: 11500, Average batch training loss: 14.46533973200425\n",
      "Iterations: 11600, Total iterations: 11600, Average batch training loss: 14.43258127253631\n",
      "Iterations: 11700, Total iterations: 11700, Average batch training loss: 14.404611307087107\n",
      "Iterations: 11800, Total iterations: 11800, Average batch training loss: 14.372975621950829\n",
      "Iterations: 13000, Total iterations: 13000, Average batch training loss: 14.014055072399286\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 13000: Average validation loss = 3.2428767159581184\n",
      "Iteration 13000: Average validation metric = 5.106905374675989\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 13100, Total iterations: 13100, Average batch training loss: 13.986152345624589\n",
      "Iterations: 13200, Total iterations: 13200, Average batch training loss: 13.957848416729407\n",
      "Iterations: 13300, Total iterations: 13300, Average batch training loss: 13.928896057677449\n",
      "Iterations: 13400, Total iterations: 13400, Average batch training loss: 13.895411231855848\n",
      "Iterations: 13500, Total iterations: 13500, Average batch training loss: 13.869432692298183\n",
      "Iterations: 13600, Total iterations: 13600, Average batch training loss: 13.844826393425464\n",
      "Iterations: 13700, Total iterations: 13700, Average batch training loss: 13.816578139301635\n",
      "Iterations: 13800, Total iterations: 13800, Average batch training loss: 13.79006222764651\n",
      "Iterations: 13900, Total iterations: 13900, Average batch training loss: 13.762703196041876\n",
      "Iterations: 14000, Total iterations: 14000, Average batch training loss: 13.739172742656299\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 14000: Average validation loss = 3.1601395830512047\n",
      "Iteration 14000: Average validation metric = 4.985837105661631\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 14100, Total iterations: 14100, Average batch training loss: 13.713662392822563\n",
      "Iterations: 14200, Total iterations: 14200, Average batch training loss: 13.686819610679652\n",
      "Iterations: 14300, Total iterations: 14300, Average batch training loss: 13.658423565267682\n",
      "Iterations: 14400, Total iterations: 14400, Average batch training loss: 13.629404623127646\n",
      "Iterations: 14500, Total iterations: 14500, Average batch training loss: 13.602354170190877\n",
      "Iterations: 14600, Total iterations: 14600, Average batch training loss: 13.578712575321328\n",
      "Iterations: 14700, Total iterations: 14700, Average batch training loss: 13.552198219737228\n",
      "Iterations: 14800, Total iterations: 14800, Average batch training loss: 13.527620780000815\n",
      "Iterations: 14900, Total iterations: 14900, Average batch training loss: 13.502535611943111\n",
      "Iterations: 15000, Total iterations: 15000, Average batch training loss: 13.47726213965416\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 15000: Average validation loss = 3.139589309692383\n",
      "Iteration 15000: Average validation metric = 4.952934220433235\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 15100, Total iterations: 15100, Average batch training loss: 13.451259759261909\n",
      "Iterations: 15200, Total iterations: 15200, Average batch training loss: 13.431815449140574\n",
      "Iterations: 15300, Total iterations: 15300, Average batch training loss: 13.410406005912357\n",
      "Iterations: 16500, Total iterations: 16500, Average batch training loss: 13.1277567226959\n",
      "Iterations: 16600, Total iterations: 16600, Average batch training loss: 13.10397240611444\n",
      "Iterations: 16700, Total iterations: 16700, Average batch training loss: 13.079514587525122\n",
      "Iterations: 16800, Total iterations: 16800, Average batch training loss: 13.054707685297444\n",
      "Iterations: 16900, Total iterations: 16900, Average batch training loss: 13.029825854287346\n",
      "Iterations: 17000, Total iterations: 17000, Average batch training loss: 13.009084094860974\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 17000: Average validation loss = 2.8299609143286943\n",
      "Iteration 17000: Average validation metric = 4.464516669511795\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 17100, Total iterations: 17100, Average batch training loss: 12.98590246984136\n",
      "Iterations: 17200, Total iterations: 17200, Average batch training loss: 12.96197336776312\n",
      "Iterations: 17300, Total iterations: 17300, Average batch training loss: 12.943488139968387\n",
      "Iterations: 17400, Total iterations: 17400, Average batch training loss: 12.919483954303566\n",
      "Iterations: 17500, Total iterations: 17500, Average batch training loss: 12.900663610158647\n",
      "Iterations: 17600, Total iterations: 17600, Average batch training loss: 12.880873363180594\n",
      "Iterations: 17700, Total iterations: 17700, Average batch training loss: 12.861043082846086\n",
      "Iterations: 17800, Total iterations: 17800, Average batch training loss: 12.84091413215305\n",
      "Iterations: 17900, Total iterations: 17900, Average batch training loss: 12.821219403397437\n",
      "Iterations: 18000, Total iterations: 18000, Average batch training loss: 12.801278741690847\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 18000: Average validation loss = 2.7399607338011265\n",
      "Iteration 18000: Average validation metric = 4.322526525706053\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 18100, Total iterations: 18100, Average batch training loss: 12.78151215670517\n",
      "Iterations: 18200, Total iterations: 18200, Average batch training loss: 12.758667156971418\n",
      "Iterations: 18300, Total iterations: 18300, Average batch training loss: 12.737838899620243\n",
      "Iterations: 18400, Total iterations: 18400, Average batch training loss: 12.713098747587722\n",
      "Iterations: 18500, Total iterations: 18500, Average batch training loss: 12.691934136919073\n",
      "Iterations: 18600, Total iterations: 18600, Average batch training loss: 12.672970878526728\n",
      "Iterations: 18700, Total iterations: 18700, Average batch training loss: 12.653139563486539\n",
      "Iterations: 18800, Total iterations: 18800, Average batch training loss: 12.63211376399436\n",
      "Iterations: 18900, Total iterations: 18900, Average batch training loss: 12.613062518475548\n",
      "Iterations: 19000, Total iterations: 19000, Average batch training loss: 12.591019815557882\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 19000: Average validation loss = 2.8051008712500334\n",
      "Iteration 19000: Average validation metric = 4.42673872038722\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 19100, Total iterations: 19100, Average batch training loss: 12.57148749415163\n",
      "Iterations: 19200, Total iterations: 19200, Average batch training loss: 12.553107292925318\n",
      "Iterations: 19300, Total iterations: 19300, Average batch training loss: 12.535535279444462\n",
      "Iterations: 19400, Total iterations: 19400, Average batch training loss: 12.517898143763395\n",
      "Iterations: 19500, Total iterations: 19500, Average batch training loss: 12.496262574146956\n",
      "Iterations: 19600, Total iterations: 19600, Average batch training loss: 12.4760389245043\n",
      "Iterations: 19700, Total iterations: 19700, Average batch training loss: 12.45980014425849\n",
      "Iterations: 19800, Total iterations: 19800, Average batch training loss: 12.438151948283418\n",
      "Iterations: 19900, Total iterations: 19900, Average batch training loss: 12.41774578190329\n",
      "Iterations: 20000, Total iterations: 20000, Average batch training loss: 12.398135995602608\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 20000: Average validation loss = 2.5814715698361397\n",
      "Iteration 20000: Average validation metric = 4.070293340831995\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 20100, Total iterations: 20100, Average batch training loss: 12.378621721445624\n",
      "Iterations: 20200, Total iterations: 20200, Average batch training loss: 12.359561185683354\n",
      "Iterations: 20300, Total iterations: 20300, Average batch training loss: 12.340785024588918\n",
      "Iterations: 20400, Total iterations: 20400, Average batch training loss: 12.320349222339836\n",
      "Iterations: 20500, Total iterations: 20500, Average batch training loss: 12.298407267768209\n",
      "Iterations: 20600, Total iterations: 20600, Average batch training loss: 12.279281409052968\n",
      "Iterations: 20700, Total iterations: 20700, Average batch training loss: 12.25845040064503\n",
      "Iterations: 20800, Total iterations: 20800, Average batch training loss: 12.241015717398662\n",
      "Iterations: 20900, Total iterations: 20900, Average batch training loss: 12.223543227186614\n",
      "Iterations: 21000, Total iterations: 21000, Average batch training loss: 12.203532545260021\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 21000: Average validation loss = 2.5530967079102993\n",
      "Iteration 21000: Average validation metric = 4.025484021753073\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 21100, Total iterations: 21100, Average batch training loss: 12.187428596867205\n",
      "Iterations: 21200, Total iterations: 21200, Average batch training loss: 12.168246111509935\n",
      "Iterations: 21300, Total iterations: 21300, Average batch training loss: 12.148876884352992\n",
      "Iterations: 21400, Total iterations: 21400, Average batch training loss: 12.13076791640754\n",
      "Iterations: 21500, Total iterations: 21500, Average batch training loss: 12.110855165947315\n",
      "Iterations: 21600, Total iterations: 21600, Average batch training loss: 12.0918128285695\n",
      "Iterations: 21700, Total iterations: 21700, Average batch training loss: 12.07557177333788\n",
      "Iterations: 21800, Total iterations: 21800, Average batch training loss: 12.058650683755175\n",
      "Iterations: 21900, Total iterations: 21900, Average batch training loss: 12.042947996424758\n",
      "Iterations: 22000, Total iterations: 22000, Average batch training loss: 12.025070878245614\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 22000: Average validation loss = 2.5058713257312775\n",
      "Iteration 22000: Average validation metric = 3.9509558863937855\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 22100, Total iterations: 22100, Average batch training loss: 12.005953468596774\n",
      "Iterations: 22200, Total iterations: 22200, Average batch training loss: 11.990042789122006\n",
      "Iterations: 22300, Total iterations: 22300, Average batch training loss: 11.971247150256495\n",
      "Iterations: 22400, Total iterations: 22400, Average batch training loss: 11.9568107653835\n",
      "Iterations: 22500, Total iterations: 22500, Average batch training loss: 11.938628076140086\n",
      "Iterations: 22600, Total iterations: 22600, Average batch training loss: 11.920500589419255\n",
      "Iterations: 22700, Total iterations: 22700, Average batch training loss: 11.902061178663228\n",
      "Iterations: 22800, Total iterations: 22800, Average batch training loss: 11.885797168947104\n",
      "Iterations: 22900, Total iterations: 22900, Average batch training loss: 11.867810638929559\n",
      "Iterations: 23000, Total iterations: 23000, Average batch training loss: 11.848488089924274\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 23000: Average validation loss = 2.397774111479521\n",
      "Iteration 23000: Average validation metric = 3.784075006842613\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 23100, Total iterations: 23100, Average batch training loss: 11.831995070620533\n",
      "Iterations: 23200, Total iterations: 23200, Average batch training loss: 11.816305380206684\n",
      "Iterations: 23300, Total iterations: 23300, Average batch training loss: 11.79783920612458\n",
      "Iterations: 23400, Total iterations: 23400, Average batch training loss: 11.781304244006801\n",
      "Iterations: 23500, Total iterations: 23500, Average batch training loss: 11.765201712811248\n",
      "Iterations: 23600, Total iterations: 23600, Average batch training loss: 11.748785091386003\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3275ca2-d263-45a6-9f46-57955c14dd2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Traning output 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cac77d-eb32-400f-b146-8d6bdd6cef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: SequenceLoss is initialized!\n",
      "Optimizer: AdamW is initialized!\n",
      "Scheduler: OneCycleLR is initialized!\n",
      "Training config:\n",
      "\n",
      "CKPT_DIR: ../../results/crossflow/ckpts/exp003\n",
      "CKPT_INTERVAL: 20000\n",
      "CRITERION:\n",
      "  CUSTOM: True\n",
      "  NAME: SequenceLoss\n",
      "  PARAMS:\n",
      "    gamma: 0.8\n",
      "    max_flow: 400.0\n",
      "DATA:\n",
      "  APPEND_VALID_MASK: True\n",
      "  AUGMENTATION:\n",
      "    PARAMS:\n",
      "      TRAINING:\n",
      "        AUTOFLOW_SPATIAL_PARAMS:\n",
      "          black: False\n",
      "          enabled: False\n",
      "          rot: [0.4, 0.03]\n",
      "          scale: [0.3, 0.03, 0.1]\n",
      "          squeeze: [0.3, 0.0]\n",
      "          trans: [0.4, 0.03]\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.2\n",
      "          brightness: 0.4\n",
      "          contrast: 0.4\n",
      "          enabled: True\n",
      "          hue: 0.15915494309189535\n",
      "          saturation: 0.4\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          bounds: [50, 100]\n",
      "          enabled: True\n",
      "        NOISE_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          enabled: False\n",
      "          noise_std_range: 0.06\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.8\n",
      "          enabled: True\n",
      "          flip: True\n",
      "          h_flip_prob: 0.5\n",
      "          max_scale: 1.0\n",
      "          max_stretch: 0.2\n",
      "          min_scale: -0.1\n",
      "          stretch_prob: 0.8\n",
      "          v_flip_prob: 0.1\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "      VALIDATION:\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "    USE: True\n",
      "  BATCH_SIZE: 10\n",
      "  NORM_PARAMS:\n",
      "    mean: [0.485, 0.456, 0.406]\n",
      "    std: [0.229, 0.224, 0.225]\n",
      "    use: True\n",
      "  NUM_WORKERS: 4\n",
      "  PIN_MEMORY: True\n",
      "  SHUFFLE: True\n",
      "  TRAIN_CROP_SIZE: [384, 512]\n",
      "  TRAIN_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "  VAL_CROP_SIZE: [384, 512]\n",
      "  VAL_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "DEVICE: 0\n",
      "DISTRIBUTED:\n",
      "  BACKEND: nccl\n",
      "  MASTER_ADDR: localhost\n",
      "  MASTER_PORT: 12355\n",
      "  SYNC_BATCH_NORM: True\n",
      "  USE: False\n",
      "  WORLD_SIZE: 4\n",
      "EPOCHS: None\n",
      "FREEZE_BATCH_NORM: False\n",
      "GRAD_CLIP:\n",
      "  USE: True\n",
      "  VALUE: 1.0\n",
      "LOG_DIR: ../../results/crossflow/logs/exp003\n",
      "LOG_ITERATIONS_INTERVAL: 100\n",
      "MIXED_PRECISION: False\n",
      "NUM_STEPS: 50000\n",
      "OPTIMIZER:\n",
      "  LR: 0.0004\n",
      "  NAME: AdamW\n",
      "  PARAMS:\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    eps: 1e-08\n",
      "    weight_decay: 0.0001\n",
      "RESUME_TRAINING:\n",
      "  CONSOLIDATED_CKPT: None\n",
      "  EPOCHS: 100\n",
      "  START_EPOCH: None\n",
      "SCHEDULER:\n",
      "  NAME: OneCycleLR\n",
      "  PARAMS:\n",
      "    anneal_strategy: linear\n",
      "    cycle_momentum: False\n",
      "    max_lr: 0.0004\n",
      "    pct_start: 0.05\n",
      "    total_steps: 50100\n",
      "  USE: True\n",
      "TARGET_SCALE_FACTOR: 1.0\n",
      "VALIDATE_INTERVAL: 1000\n",
      "VALIDATE_ON: metric\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Starting step 1 of 50001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811797118/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 100, Total iterations: 100, Average batch training loss: 39.230209560394286\n",
      "Iterations: 200, Total iterations: 200, Average batch training loss: 30.188817505836486\n",
      "Iterations: 300, Total iterations: 300, Average batch training loss: 27.124033584594727\n",
      "Iterations: 400, Total iterations: 400, Average batch training loss: 25.11518214941025\n",
      "Iterations: 500, Total iterations: 500, Average batch training loss: 23.938732753753662\n",
      "Iterations: 600, Total iterations: 600, Average batch training loss: 22.988590288162232\n",
      "Iterations: 700, Total iterations: 700, Average batch training loss: 22.328436083112443\n",
      "Iterations: 800, Total iterations: 800, Average batch training loss: 21.879796508550644\n",
      "Iterations: 900, Total iterations: 900, Average batch training loss: 21.528786935806274\n",
      "Iterations: 1000, Total iterations: 1000, Average batch training loss: 21.203034631729125\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1000: Average validation loss = 7.0863893032073975\n",
      "Iteration 1000: Average validation metric = 11.03139578551054\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 1100, Total iterations: 1100, Average batch training loss: 20.944756010228936\n",
      "Iterations: 1200, Total iterations: 1200, Average batch training loss: 20.702463808059694\n",
      "Iterations: 1300, Total iterations: 1300, Average batch training loss: 20.544698545015777\n",
      "Iterations: 1400, Total iterations: 1400, Average batch training loss: 20.37012470177242\n",
      "Iterations: 1500, Total iterations: 1500, Average batch training loss: 20.141371988932292\n",
      "Iterations: 1600, Total iterations: 1600, Average batch training loss: 19.99656514763832\n",
      "Iterations: 1700, Total iterations: 1700, Average batch training loss: 19.840588417614207\n",
      "Iterations: 1800, Total iterations: 1800, Average batch training loss: 19.70347660223643\n",
      "Iterations: 1900, Total iterations: 1900, Average batch training loss: 19.590959226708662\n",
      "Iterations: 2000, Total iterations: 2000, Average batch training loss: 19.43932732486725\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2000: Average validation loss = 6.264612730592489\n",
      "Iteration 2000: Average validation metric = 9.8052674010396\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 2100, Total iterations: 2100, Average batch training loss: 19.28566764309293\n",
      "Iterations: 2200, Total iterations: 2200, Average batch training loss: 19.12903345346451\n",
      "Iterations: 2300, Total iterations: 2300, Average batch training loss: 18.997446081949317\n",
      "Iterations: 2400, Total iterations: 2400, Average batch training loss: 18.907409628828365\n",
      "Iterations: 2500, Total iterations: 2500, Average batch training loss: 18.80967614955902\n",
      "Iterations: 2600, Total iterations: 2600, Average batch training loss: 18.682660962434916\n",
      "Iterations: 2700, Total iterations: 2700, Average batch training loss: 18.516935795501425\n",
      "Iterations: 2800, Total iterations: 2800, Average batch training loss: 18.3639657502515\n",
      "Iterations: 2900, Total iterations: 2900, Average batch training loss: 18.256417001691357\n",
      "Iterations: 3000, Total iterations: 3000, Average batch training loss: 18.12965188995997\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3000: Average validation loss = 5.204696666449308\n",
      "Iteration 3000: Average validation metric = 8.180731505155563\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 3100, Total iterations: 3100, Average batch training loss: 18.042741228688147\n",
      "Iterations: 3200, Total iterations: 3200, Average batch training loss: 17.924745881706475\n",
      "Iterations: 3300, Total iterations: 3300, Average batch training loss: 17.817219726822593\n",
      "Iterations: 3400, Total iterations: 3400, Average batch training loss: 17.72778086536071\n",
      "Iterations: 3500, Total iterations: 3500, Average batch training loss: 17.63205566910335\n",
      "Iterations: 3600, Total iterations: 3600, Average batch training loss: 17.546523682673772\n",
      "Iterations: 3700, Total iterations: 3700, Average batch training loss: 17.458678627143033\n",
      "Iterations: 3800, Total iterations: 3800, Average batch training loss: 17.366042538316627\n",
      "Iterations: 3900, Total iterations: 3900, Average batch training loss: 17.268784271998282\n",
      "Iterations: 4000, Total iterations: 4000, Average batch training loss: 17.197347692370414\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4000: Average validation loss = 4.698751848191023\n",
      "Iteration 4000: Average validation metric = 7.396291367709637\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 4100, Total iterations: 4100, Average batch training loss: 17.130293901141098\n",
      "Iterations: 4200, Total iterations: 4200, Average batch training loss: 17.070895190806617\n",
      "Iterations: 4300, Total iterations: 4300, Average batch training loss: 16.98853279135948\n",
      "Iterations: 4400, Total iterations: 4400, Average batch training loss: 16.910123072320765\n",
      "Iterations: 4500, Total iterations: 4500, Average batch training loss: 16.84089432144165\n",
      "Iterations: 4600, Total iterations: 4600, Average batch training loss: 16.769567958997644\n",
      "Iterations: 4700, Total iterations: 4700, Average batch training loss: 16.69670353087973\n",
      "Iterations: 4800, Total iterations: 4800, Average batch training loss: 16.626279987096787\n",
      "Iterations: 4900, Total iterations: 4900, Average batch training loss: 16.56074008357768\n",
      "Iterations: 5000, Total iterations: 5000, Average batch training loss: 16.48384612283707\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5000: Average validation loss = 4.314339231699705\n",
      "Iteration 5000: Average validation metric = 6.776333577930927\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 5100, Total iterations: 5100, Average batch training loss: 16.418503738945606\n",
      "Iterations: 5200, Total iterations: 5200, Average batch training loss: 16.37793492601468\n",
      "Iterations: 5300, Total iterations: 5300, Average batch training loss: 16.326279904257575\n",
      "Iterations: 5400, Total iterations: 5400, Average batch training loss: 16.265692326227825\n",
      "Iterations: 5500, Total iterations: 5500, Average batch training loss: 16.20155954985185\n",
      "Iterations: 5600, Total iterations: 5600, Average batch training loss: 16.153414637446403\n",
      "Iterations: 5700, Total iterations: 5700, Average batch training loss: 16.086394488016765\n",
      "Iterations: 5800, Total iterations: 5800, Average batch training loss: 16.038203185180137\n",
      "Iterations: 5900, Total iterations: 5900, Average batch training loss: 15.98140542887025\n",
      "Iterations: 6000, Total iterations: 6000, Average batch training loss: 15.923598896980286\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6000: Average validation loss = 4.190030921250582\n",
      "Iteration 6000: Average validation metric = 6.599546570330858\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 6100, Total iterations: 6100, Average batch training loss: 15.860793503151566\n",
      "Iterations: 6200, Total iterations: 6200, Average batch training loss: 15.825086653078756\n",
      "Iterations: 6300, Total iterations: 6300, Average batch training loss: 15.792699735353864\n",
      "Iterations: 6400, Total iterations: 6400, Average batch training loss: 15.747229906022548\n",
      "Iterations: 6500, Total iterations: 6500, Average batch training loss: 15.699511550463162\n",
      "Iterations: 6600, Total iterations: 6600, Average batch training loss: 15.654861761584426\n",
      "Iterations: 6700, Total iterations: 6700, Average batch training loss: 15.604322556666474\n",
      "Iterations: 6800, Total iterations: 6800, Average batch training loss: 15.564033822382198\n",
      "Iterations: 6900, Total iterations: 6900, Average batch training loss: 15.522946157939192\n",
      "Iterations: 7000, Total iterations: 7000, Average batch training loss: 15.472329123701368\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7000: Average validation loss = 3.9834441989660263\n",
      "Iteration 7000: Average validation metric = 6.268578000366688\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 7100, Total iterations: 7100, Average batch training loss: 15.41575463697944\n",
      "Iterations: 7200, Total iterations: 7200, Average batch training loss: 15.375633834136856\n",
      "Iterations: 7300, Total iterations: 7300, Average batch training loss: 15.331451797420032\n",
      "Iterations: 7400, Total iterations: 7400, Average batch training loss: 15.295270053953738\n",
      "Iterations: 7500, Total iterations: 7500, Average batch training loss: 15.264885364023844\n",
      "Iterations: 7600, Total iterations: 7600, Average batch training loss: 15.218004760052029\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc5ce5-42cf-4380-97f3-2ba6c975444e",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "## Training output 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7f8f8-81b6-4730-9c58-91791b2f8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: SequenceLoss is initialized!\n",
      "Optimizer: AdamW is initialized!\n",
      "Scheduler: OneCycleLR is initialized!\n",
      "Training config:\n",
      "\n",
      "CKPT_DIR: ../../results/crossflow/ckpts/exp004\n",
      "CKPT_INTERVAL: 20000\n",
      "CRITERION:\n",
      "  CUSTOM: True\n",
      "  NAME: SequenceLoss\n",
      "  PARAMS:\n",
      "    gamma: 0.8\n",
      "    max_flow: 400.0\n",
      "DATA:\n",
      "  APPEND_VALID_MASK: True\n",
      "  AUGMENTATION:\n",
      "    PARAMS:\n",
      "      TRAINING:\n",
      "        AUTOFLOW_SPATIAL_PARAMS:\n",
      "          black: False\n",
      "          enabled: False\n",
      "          rot: [0.4, 0.03]\n",
      "          scale: [0.3, 0.03, 0.1]\n",
      "          squeeze: [0.3, 0.0]\n",
      "          trans: [0.4, 0.03]\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.2\n",
      "          brightness: 0.4\n",
      "          contrast: 0.4\n",
      "          enabled: True\n",
      "          hue: 0.15915494309189535\n",
      "          saturation: 0.4\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          bounds: [50, 100]\n",
      "          enabled: True\n",
      "        NOISE_PARAMS:\n",
      "          aug_prob: 0.5\n",
      "          enabled: False\n",
      "          noise_std_range: 0.06\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.8\n",
      "          enabled: True\n",
      "          flip: True\n",
      "          h_flip_prob: 0.5\n",
      "          max_scale: 1.0\n",
      "          max_stretch: 0.2\n",
      "          min_scale: -0.1\n",
      "          stretch_prob: 0.8\n",
      "          v_flip_prob: 0.1\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "      VALIDATION:\n",
      "        COLOR_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ERASER_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        ROTATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        SPATIAL_AUG_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "        TRANSLATE_PARAMS:\n",
      "          aug_prob: 0.0\n",
      "          enabled: False\n",
      "    USE: True\n",
      "  BATCH_SIZE: 10\n",
      "  NORM_PARAMS:\n",
      "    mean: [0.485, 0.456, 0.406]\n",
      "    std: [0.229, 0.224, 0.225]\n",
      "    use: True\n",
      "  NUM_WORKERS: 4\n",
      "  PIN_MEMORY: True\n",
      "  SHUFFLE: True\n",
      "  TRAIN_CROP_SIZE: [384, 512]\n",
      "  TRAIN_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "  VAL_CROP_SIZE: [384, 512]\n",
      "  VAL_DATASET:\n",
      "    NAME: flyingchairs\n",
      "    ROOT_DIR: ../../../Datasets/FlyingChairs_release/data\n",
      "DEVICE: 0\n",
      "DISTRIBUTED:\n",
      "  BACKEND: nccl\n",
      "  MASTER_ADDR: localhost\n",
      "  MASTER_PORT: 12355\n",
      "  SYNC_BATCH_NORM: True\n",
      "  USE: False\n",
      "  WORLD_SIZE: 4\n",
      "EPOCHS: None\n",
      "FREEZE_BATCH_NORM: False\n",
      "GRAD_CLIP:\n",
      "  USE: True\n",
      "  VALUE: 1.0\n",
      "LOG_DIR: ../../results/crossflow/logs/exp004\n",
      "LOG_ITERATIONS_INTERVAL: 100\n",
      "MIXED_PRECISION: False\n",
      "NUM_STEPS: 50000\n",
      "OPTIMIZER:\n",
      "  LR: 0.0004\n",
      "  NAME: AdamW\n",
      "  PARAMS:\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    eps: 1e-08\n",
      "    weight_decay: 0.0001\n",
      "RESUME_TRAINING:\n",
      "  CONSOLIDATED_CKPT: None\n",
      "  EPOCHS: 100\n",
      "  START_EPOCH: None\n",
      "SCHEDULER:\n",
      "  NAME: OneCycleLR\n",
      "  PARAMS:\n",
      "    anneal_strategy: linear\n",
      "    cycle_momentum: False\n",
      "    max_lr: 0.0004\n",
      "    pct_start: 0.05\n",
      "    total_steps: 50100\n",
      "  USE: True\n",
      "TARGET_SCALE_FACTOR: 1.0\n",
      "VALIDATE_INTERVAL: 1000\n",
      "VALIDATE_ON: metric\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Starting step 1 of 50001\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/nnflow-0.0.0-py3.7.egg/nnflow/models/gmflow/position.py:39: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "/home/goswami.p/miniconda3/envs/ezflow/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811797118/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 100, Total iterations: 100, Average batch training loss: 38.806310939788816\n",
      "Iterations: 200, Total iterations: 200, Average batch training loss: 29.86527271270752\n",
      "Iterations: 300, Total iterations: 300, Average batch training loss: 26.4670383644104\n",
      "Iterations: 400, Total iterations: 400, Average batch training loss: 24.626682333946228\n",
      "Iterations: 500, Total iterations: 500, Average batch training loss: 23.34748571586609\n",
      "Iterations: 600, Total iterations: 600, Average batch training loss: 22.67428199450175\n",
      "Iterations: 700, Total iterations: 700, Average batch training loss: 22.064218209130424\n",
      "Iterations: 800, Total iterations: 800, Average batch training loss: 21.582395669817924\n",
      "Iterations: 900, Total iterations: 900, Average batch training loss: 21.205847839249504\n",
      "Iterations: 1000, Total iterations: 1000, Average batch training loss: 20.946390319347383\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 1000: Average validation loss = 7.138729572296143\n",
      "Iteration 1000: Average validation metric = 11.112779006361961\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 1100, Total iterations: 1100, Average batch training loss: 20.648134492093867\n",
      "Iterations: 1200, Total iterations: 1200, Average batch training loss: 20.517444015343983\n",
      "Iterations: 1300, Total iterations: 1300, Average batch training loss: 20.334083971610436\n",
      "Iterations: 1400, Total iterations: 1400, Average batch training loss: 20.163771434511457\n",
      "Iterations: 1500, Total iterations: 1500, Average batch training loss: 20.011193342844646\n",
      "Iterations: 1600, Total iterations: 1600, Average batch training loss: 19.84063443005085\n",
      "Iterations: 1700, Total iterations: 1700, Average batch training loss: 19.650022422566135\n",
      "Iterations: 1800, Total iterations: 1800, Average batch training loss: 19.51111538251241\n",
      "Iterations: 1900, Total iterations: 1900, Average batch training loss: 19.399241688878913\n",
      "Iterations: 2000, Total iterations: 2000, Average batch training loss: 19.24735207271576\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 2000: Average validation loss = 5.750466071069241\n",
      "Iteration 2000: Average validation metric = 9.03166376799345\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 2100, Total iterations: 2100, Average batch training loss: 19.095603667213805\n",
      "Iterations: 2200, Total iterations: 2200, Average batch training loss: 18.926011908271096\n",
      "Iterations: 2300, Total iterations: 2300, Average batch training loss: 18.754551630849424\n",
      "Iterations: 2400, Total iterations: 2400, Average batch training loss: 18.63595142801603\n",
      "Iterations: 2500, Total iterations: 2500, Average batch training loss: 18.518409239959716\n",
      "Iterations: 2600, Total iterations: 2600, Average batch training loss: 18.403830427756677\n",
      "Iterations: 2700, Total iterations: 2700, Average batch training loss: 18.28082199803105\n",
      "Iterations: 2800, Total iterations: 2800, Average batch training loss: 18.14943920986993\n",
      "Iterations: 2900, Total iterations: 2900, Average batch training loss: 18.036060549308512\n",
      "Iterations: 3000, Total iterations: 3000, Average batch training loss: 17.88732840935389\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 3000: Average validation loss = 5.037812788039446\n",
      "Iteration 3000: Average validation metric = 7.930194742977619\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 3100, Total iterations: 3100, Average batch training loss: 17.774881738539666\n",
      "Iterations: 3200, Total iterations: 3200, Average batch training loss: 17.655899185687304\n",
      "Iterations: 3300, Total iterations: 3300, Average batch training loss: 17.52874908143824\n",
      "Iterations: 3400, Total iterations: 3400, Average batch training loss: 17.410099666819853\n",
      "Iterations: 3500, Total iterations: 3500, Average batch training loss: 17.32695383140019\n",
      "Iterations: 3600, Total iterations: 3600, Average batch training loss: 17.20846899681621\n",
      "Iterations: 3700, Total iterations: 3700, Average batch training loss: 17.09385414329735\n",
      "Iterations: 3800, Total iterations: 3800, Average batch training loss: 16.983252023772188\n",
      "Iterations: 3900, Total iterations: 3900, Average batch training loss: 16.89885515408638\n",
      "Iterations: 4000, Total iterations: 4000, Average batch training loss: 16.804827300429345\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 4000: Average validation loss = 4.621585361659527\n",
      "Iteration 4000: Average validation metric = 7.26645739749074\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 4100, Total iterations: 4100, Average batch training loss: 16.71653992792455\n",
      "Iterations: 4200, Total iterations: 4200, Average batch training loss: 16.638948589506604\n",
      "Iterations: 4300, Total iterations: 4300, Average batch training loss: 16.5525044733979\n",
      "Iterations: 4400, Total iterations: 4400, Average batch training loss: 16.455959254394877\n",
      "Iterations: 4500, Total iterations: 4500, Average batch training loss: 16.365149768511454\n",
      "Iterations: 4600, Total iterations: 4600, Average batch training loss: 16.286814449144448\n",
      "Iterations: 4700, Total iterations: 4700, Average batch training loss: 16.211722818739872\n",
      "Iterations: 4800, Total iterations: 4800, Average batch training loss: 16.144315028389293\n",
      "Iterations: 4900, Total iterations: 4900, Average batch training loss: 16.061410047861994\n",
      "Iterations: 5000, Total iterations: 5000, Average batch training loss: 15.980921416950226\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 5000: Average validation loss = 4.23685535416007\n",
      "Iteration 5000: Average validation metric = 6.656516395509243\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 5100, Total iterations: 5100, Average batch training loss: 15.903155014468174\n",
      "Iterations: 5200, Total iterations: 5200, Average batch training loss: 15.829824148783317\n",
      "Iterations: 5300, Total iterations: 5300, Average batch training loss: 15.766391393463566\n",
      "Iterations: 5400, Total iterations: 5400, Average batch training loss: 15.690970059412496\n",
      "Iterations: 5500, Total iterations: 5500, Average batch training loss: 15.626331259814176\n",
      "Iterations: 5600, Total iterations: 5600, Average batch training loss: 15.561931195259094\n",
      "Iterations: 5700, Total iterations: 5700, Average batch training loss: 15.505974685016431\n",
      "Iterations: 5800, Total iterations: 5800, Average batch training loss: 15.45062812632528\n",
      "Iterations: 5900, Total iterations: 5900, Average batch training loss: 15.393366835723489\n",
      "Iterations: 6000, Total iterations: 6000, Average batch training loss: 15.32269385266304\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 6000: Average validation loss = 3.846619538962841\n",
      "Iteration 6000: Average validation metric = 6.045233119279146\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 6100, Total iterations: 6100, Average batch training loss: 15.255740340654967\n",
      "Iterations: 6200, Total iterations: 6200, Average batch training loss: 15.200796487023753\n",
      "Iterations: 6300, Total iterations: 6300, Average batch training loss: 15.143473902127099\n",
      "Iterations: 6400, Total iterations: 6400, Average batch training loss: 15.08926517918706\n",
      "Iterations: 6500, Total iterations: 6500, Average batch training loss: 15.04653763477619\n",
      "Iterations: 6600, Total iterations: 6600, Average batch training loss: 14.986968162059783\n",
      "Iterations: 6700, Total iterations: 6700, Average batch training loss: 14.926667114229344\n",
      "Iterations: 6800, Total iterations: 6800, Average batch training loss: 14.860685196694206\n",
      "Iterations: 6900, Total iterations: 6900, Average batch training loss: 14.819656787886135\n",
      "Iterations: 7000, Total iterations: 7000, Average batch training loss: 14.76452793782098\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 7000: Average validation loss = 3.6944951452314854\n",
      "Iteration 7000: Average validation metric = 5.798439387232065\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 7100, Total iterations: 7100, Average batch training loss: 14.709194333183934\n",
      "Iterations: 7200, Total iterations: 7200, Average batch training loss: 14.658721229434013\n",
      "Iterations: 7300, Total iterations: 7300, Average batch training loss: 14.604977909506184\n",
      "Iterations: 7400, Total iterations: 7400, Average batch training loss: 14.552202408249313\n",
      "Iterations: 7500, Total iterations: 7500, Average batch training loss: 14.497172344144186\n",
      "Iterations: 7600, Total iterations: 7600, Average batch training loss: 14.451702658690904\n",
      "Iterations: 7700, Total iterations: 7700, Average batch training loss: 14.407424608887016\n",
      "Iterations: 7800, Total iterations: 7800, Average batch training loss: 14.35939668251918\n",
      "Iterations: 7900, Total iterations: 7900, Average batch training loss: 14.311585246882862\n",
      "Iterations: 8000, Total iterations: 8000, Average batch training loss: 14.27176035529375\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 8000: Average validation loss = 3.3969173710793257\n",
      "Iteration 8000: Average validation metric = 5.325997930020094\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 8100, Total iterations: 8100, Average batch training loss: 14.22582062114904\n",
      "Iterations: 8200, Total iterations: 8200, Average batch training loss: 14.192825386582351\n",
      "Iterations: 8300, Total iterations: 8300, Average batch training loss: 14.146343481282154\n",
      "Iterations: 8400, Total iterations: 8400, Average batch training loss: 14.106974343231746\n",
      "Iterations: 8500, Total iterations: 8500, Average batch training loss: 14.061773726070628\n",
      "Iterations: 8600, Total iterations: 8600, Average batch training loss: 14.0196605908039\n",
      "Iterations: 8700, Total iterations: 8700, Average batch training loss: 13.97173780792061\n",
      "Iterations: 8800, Total iterations: 8800, Average batch training loss: 13.93444822495634\n",
      "Iterations: 8900, Total iterations: 8900, Average batch training loss: 13.89237490455756\n",
      "Iterations: 9000, Total iterations: 9000, Average batch training loss: 13.84450347773234\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 9000: Average validation loss = 3.284166481345892\n",
      "Iteration 9000: Average validation metric = 5.158130306750536\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 9100, Total iterations: 9100, Average batch training loss: 13.807848004299206\n",
      "Iterations: 9200, Total iterations: 9200, Average batch training loss: 13.7639031786504\n",
      "Iterations: 9300, Total iterations: 9300, Average batch training loss: 13.725253522575542\n",
      "Iterations: 9400, Total iterations: 9400, Average batch training loss: 13.683124250756933\n",
      "Iterations: 9500, Total iterations: 9500, Average batch training loss: 13.646213470509178\n",
      "Iterations: 9600, Total iterations: 9600, Average batch training loss: 13.604200294415156\n",
      "Iterations: 9700, Total iterations: 9700, Average batch training loss: 13.573135407093874\n",
      "Iterations: 9800, Total iterations: 9800, Average batch training loss: 13.533996182120577\n",
      "Iterations: 9900, Total iterations: 9900, Average batch training loss: 13.490259958156432\n",
      "Iterations: 10000, Total iterations: 10000, Average batch training loss: 13.45185795686245\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 10000: Average validation loss = 3.0982030909508467\n",
      "Iteration 10000: Average validation metric = 4.859602082520723\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 10100, Total iterations: 10100, Average batch training loss: 13.416349737549773\n",
      "Iterations: 10200, Total iterations: 10200, Average batch training loss: 13.383420488109776\n",
      "Iterations: 10300, Total iterations: 10300, Average batch training loss: 13.34465706684057\n",
      "Iterations: 10400, Total iterations: 10400, Average batch training loss: 13.30717284209453\n",
      "Iterations: 10500, Total iterations: 10500, Average batch training loss: 13.269868087110066\n",
      "Iterations: 10600, Total iterations: 10600, Average batch training loss: 13.235428210631856\n",
      "Iterations: 10700, Total iterations: 10700, Average batch training loss: 13.202421704118496\n",
      "Iterations: 10800, Total iterations: 10800, Average batch training loss: 13.166596686244011\n",
      "Iterations: 10900, Total iterations: 10900, Average batch training loss: 13.125799690539683\n",
      "Iterations: 11000, Total iterations: 11000, Average batch training loss: 13.094670794465324\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 11000: Average validation loss = 3.00144056789577\n",
      "Iteration 11000: Average validation metric = 4.713720623403788\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 11100, Total iterations: 11100, Average batch training loss: 13.060101675278432\n",
      "Iterations: 11200, Total iterations: 11200, Average batch training loss: 13.026579885248626\n",
      "Iterations: 11300, Total iterations: 11300, Average batch training loss: 12.994377591314569\n",
      "Iterations: 11400, Total iterations: 11400, Average batch training loss: 12.963196771584059\n",
      "Iterations: 11500, Total iterations: 11500, Average batch training loss: 12.931949490070343\n",
      "Iterations: 11700, Total iterations: 11700, Average batch training loss: 12.865087104577285\n",
      "Iterations: 11800, Total iterations: 11800, Average batch training loss: 12.836217199341725\n",
      "Iterations: 11900, Total iterations: 11900, Average batch training loss: 12.8039387141957\n",
      "Iterations: 12000, Total iterations: 12000, Average batch training loss: 12.77497059114774\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 12000: Average validation loss = 2.7933360300958157\n",
      "Iteration 12000: Average validation metric = 4.3904196806252\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 12100, Total iterations: 12100, Average batch training loss: 12.743174857896221\n",
      "Iterations: 12200, Total iterations: 12200, Average batch training loss: 12.712584705509123\n",
      "Iterations: 12300, Total iterations: 12300, Average batch training loss: 12.678109465653334\n",
      "Iterations: 12400, Total iterations: 12400, Average batch training loss: 12.6427766130432\n",
      "Iterations: 12500, Total iterations: 12500, Average batch training loss: 12.611285513839722\n",
      "Iterations: 12600, Total iterations: 12600, Average batch training loss: 12.582196984480298\n",
      "Iterations: 12700, Total iterations: 12700, Average batch training loss: 12.552884754045742\n",
      "Iterations: 12800, Total iterations: 12800, Average batch training loss: 12.521268905196338\n",
      "Iterations: 12900, Total iterations: 12900, Average batch training loss: 12.491713279347087\n",
      "Iterations: 13000, Total iterations: 13000, Average batch training loss: 12.459140944040739\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 13000: Average validation loss = 2.7173134926706553\n",
      "Iteration 13000: Average validation metric = 4.270164214074612\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 13100, Total iterations: 13100, Average batch training loss: 12.427815195367536\n",
      "Iterations: 13200, Total iterations: 13200, Average batch training loss: 12.39768169984673\n",
      "Iterations: 13300, Total iterations: 13300, Average batch training loss: 12.36441384616651\n",
      "Iterations: 13400, Total iterations: 13400, Average batch training loss: 12.329793056053902\n",
      "Iterations: 13500, Total iterations: 13500, Average batch training loss: 12.30147253478015\n",
      "Iterations: 13600, Total iterations: 13600, Average batch training loss: 12.273592229941311\n",
      "Iterations: 13700, Total iterations: 13700, Average batch training loss: 12.244772134401503\n",
      "Iterations: 13800, Total iterations: 13800, Average batch training loss: 12.215246635226237\n",
      "Iterations: 13900, Total iterations: 13900, Average batch training loss: 12.182719186793129\n",
      "Iterations: 14000, Total iterations: 14000, Average batch training loss: 12.159682068961008\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 14000: Average validation loss = 2.5071221217513084\n",
      "Iteration 14000: Average validation metric = 3.9465185329318047\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 14100, Total iterations: 14100, Average batch training loss: 12.13314696401569\n",
      "Iterations: 14200, Total iterations: 14200, Average batch training loss: 12.103668381177204\n",
      "Iterations: 14300, Total iterations: 14300, Average batch training loss: 12.075392925805978\n",
      "Iterations: 14400, Total iterations: 14400, Average batch training loss: 12.047432604961925\n",
      "Iterations: 14500, Total iterations: 14500, Average batch training loss: 12.021507522023958\n",
      "Iterations: 14600, Total iterations: 14600, Average batch training loss: 11.993660662533486\n",
      "Iterations: 14700, Total iterations: 14700, Average batch training loss: 11.967650406863413\n",
      "Iterations: 14800, Total iterations: 14800, Average batch training loss: 11.942255306453319\n",
      "Iterations: 14900, Total iterations: 14900, Average batch training loss: 11.915706973251881\n",
      "Iterations: 15000, Total iterations: 15000, Average batch training loss: 11.884993272892634\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 15000: Average validation loss = 2.3837720043957233\n",
      "Iteration 15000: Average validation metric = 3.7487723603844643\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 15100, Total iterations: 15100, Average batch training loss: 11.860916380424372\n",
      "Iterations: 15200, Total iterations: 15200, Average batch training loss: 11.8330244035313\n",
      "Iterations: 15300, Total iterations: 15300, Average batch training loss: 11.808697751737109\n",
      "Iterations: 15400, Total iterations: 15400, Average batch training loss: 11.783059001526276\n",
      "Iterations: 15500, Total iterations: 15500, Average batch training loss: 11.757857821987521\n",
      "Iterations: 15600, Total iterations: 15600, Average batch training loss: 11.73099648607083\n",
      "Iterations: 15700, Total iterations: 15700, Average batch training loss: 11.705240309496594\n",
      "Iterations: 15800, Total iterations: 15800, Average batch training loss: 11.679027799443354\n",
      "Iterations: 15900, Total iterations: 15900, Average batch training loss: 11.650372698771879\n",
      "Iterations: 16000, Total iterations: 16000, Average batch training loss: 11.622671705290674\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 16000: Average validation loss = 2.2965505346655846\n",
      "Iteration 16000: Average validation metric = 3.61644933745265\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 16100, Total iterations: 16100, Average batch training loss: 11.597113905959988\n",
      "Iterations: 16200, Total iterations: 16200, Average batch training loss: 11.570072966828759\n",
      "Iterations: 16300, Total iterations: 16300, Average batch training loss: 11.545377551617067\n",
      "Iterations: 16400, Total iterations: 16400, Average batch training loss: 11.52288570020257\n",
      "Iterations: 16500, Total iterations: 16500, Average batch training loss: 11.496521135243503\n",
      "Iterations: 16600, Total iterations: 16600, Average batch training loss: 11.472531464846737\n",
      "Iterations: 16700, Total iterations: 16700, Average batch training loss: 11.449053226830717\n",
      "Iterations: 16800, Total iterations: 16800, Average batch training loss: 11.425120825412728\n",
      "Iterations: 16900, Total iterations: 16900, Average batch training loss: 11.40137089617859\n",
      "Iterations: 17000, Total iterations: 17000, Average batch training loss: 11.378584831279866\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 17000: Average validation loss = 2.237650480121374\n",
      "Iteration 17000: Average validation metric = 3.5307517517358065\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 17100, Total iterations: 17100, Average batch training loss: 11.354831440476646\n",
      "Iterations: 17200, Total iterations: 17200, Average batch training loss: 11.331724416585855\n",
      "Iterations: 17300, Total iterations: 17300, Average batch training loss: 11.308232749679874\n",
      "Iterations: 17400, Total iterations: 17400, Average batch training loss: 11.284966193163532\n",
      "Iterations: 17500, Total iterations: 17500, Average batch training loss: 11.260518593079704\n",
      "Iterations: 17600, Total iterations: 17600, Average batch training loss: 11.236290511163798\n",
      "Iterations: 17700, Total iterations: 17700, Average batch training loss: 11.212125532680986\n",
      "Iterations: 17800, Total iterations: 17800, Average batch training loss: 11.187820084135184\n",
      "Iterations: 17900, Total iterations: 17900, Average batch training loss: 11.163628791310934\n",
      "Iterations: 18000, Total iterations: 18000, Average batch training loss: 11.144045450621181\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 18000: Average validation loss = 2.137734390795231\n",
      "Iteration 18000: Average validation metric = 3.367164110764861\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 18100, Total iterations: 18100, Average batch training loss: 11.121991739417966\n",
      "Iterations: 18200, Total iterations: 18200, Average batch training loss: 11.09994401380256\n",
      "Iterations: 18300, Total iterations: 18300, Average batch training loss: 11.07679172289176\n",
      "Iterations: 18400, Total iterations: 18400, Average batch training loss: 11.05271533989388\n",
      "Iterations: 18500, Total iterations: 18500, Average batch training loss: 11.03257424196037\n",
      "Iterations: 18600, Total iterations: 18600, Average batch training loss: 11.010137955745062\n",
      "Iterations: 18700, Total iterations: 18700, Average batch training loss: 10.98844415729696\n",
      "Iterations: 18800, Total iterations: 18800, Average batch training loss: 10.96524289484988\n",
      "Iterations: 18900, Total iterations: 18900, Average batch training loss: 10.944453418936048\n",
      "Iterations: 19000, Total iterations: 19000, Average batch training loss: 10.923823897223723\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 19000: Average validation loss = 2.066385893151164\n",
      "Iteration 19000: Average validation metric = 3.25290996581316\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 19100, Total iterations: 19100, Average batch training loss: 10.901697396383236\n",
      "Iterations: 19200, Total iterations: 19200, Average batch training loss: 10.881120585774381\n",
      "Iterations: 19300, Total iterations: 19300, Average batch training loss: 10.858167254628295\n",
      "Iterations: 19400, Total iterations: 19400, Average batch training loss: 10.8343349196493\n",
      "Iterations: 19500, Total iterations: 19500, Average batch training loss: 10.813848391263912\n",
      "Iterations: 19600, Total iterations: 19600, Average batch training loss: 10.793831388281315\n",
      "Iterations: 19700, Total iterations: 19700, Average batch training loss: 10.773686992371747\n",
      "Iterations: 19800, Total iterations: 19800, Average batch training loss: 10.751033237149016\n",
      "Iterations: 19900, Total iterations: 19900, Average batch training loss: 10.731610353016974\n",
      "Iterations: 20000, Total iterations: 20000, Average batch training loss: 10.709250834810733\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 20000: Average validation loss = 1.9835973717272282\n",
      "Iteration 20000: Average validation metric = 3.1246745232492685\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n",
      "New minimum average validation loss!\n",
      "\n",
      "New minimum average validation metric!\n",
      "Saved new best model!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Iterations: 20100, Total iterations: 20100, Average batch training loss: 10.689365368541793\n",
      "Iterations: 20200, Total iterations: 20200, Average batch training loss: 10.667522198646376\n",
      "Iterations: 20300, Total iterations: 20300, Average batch training loss: 10.646987600032919\n",
      "Iterations: 20400, Total iterations: 20400, Average batch training loss: 10.62560600004944\n",
      "Iterations: 20500, Total iterations: 20500, Average batch training loss: 10.604159447146625\n",
      "Iterations: 20600, Total iterations: 20600, Average batch training loss: 10.58385269852518\n",
      "Iterations: 20700, Total iterations: 20700, Average batch training loss: 10.565361519274504\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7936d09-ff5f-4aa4-b92a-25114cef492c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
